{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTERODACTYL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as op\n",
    "import scipy.signal as sig\n",
    "import scipy.interpolate as interp\n",
    "from   scipy import stats\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import imp\n",
    "import timeit\n",
    "import progressbar\n",
    "import warnings\n",
    "\n",
    "import astropy\n",
    "from   astropy.io import fits as pyfits\n",
    "import lightkurve as lk\n",
    "import exoplanet as exo\n",
    "import corner\n",
    "\n",
    "sys.path.append('/Users/research/Desktop/dinosaur/pterodactyl/')\n",
    "import pterodactyl_wings as wings\n",
    "imp.reload(wings)\n",
    "\n",
    "# define constants\n",
    "pi = np.pi\n",
    "\n",
    "RJRE = 10.973      # (Rjup/Rearth)\n",
    "RSRE = 109.2       # (Rsun/Rearth)\n",
    "RSRJ = RSRE/RJRE   # (Rsun/Rjup)\n",
    "\n",
    "MJME = 317.828     # (Mjup/Mearth)\n",
    "MSME = 332948.6    # (Msun/Mearth)\n",
    "MSMJ = MSME/MJME   # (Msun/Mjup)\n",
    "\n",
    "RSAU = 0.00465     # solar radius in AU\n",
    "\n",
    "LCIT = 29.4244     # long cadence integration time (min)\n",
    "SCIT = 58.84876    # short cadence integration time (sec)\n",
    "\n",
    "# flush buffer to avoid mixed outputs from progressbar\n",
    "sys.stdout.flush()\n",
    "\n",
    "# turn off FutureWarnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# start program timer\n",
    "start = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUALLY SET GLOBAL PARAMETERS\n",
    "\n",
    "# TARGET and CSV_FILE\n",
    "TARGET   = 'K00137'\n",
    "CSV_FILE = '/Users/research/Desktop/dinosaur/pure_cks2.csv'\n",
    "\n",
    "# Which QUARTERS to use\n",
    "QSTART = 1                  # first quarter to search\n",
    "QEND   = 17                 # last quarter to search (must be a contigous block)\n",
    "NQ     = QEND-QSTART+1      # number of quarters searched\n",
    "\n",
    "# Some bad cadences to manually remove\n",
    "BAD_CADENCES = None\n",
    "\n",
    "# LM fitting parameters -- [T0, P, rp, zeta, b^2, e^1/2sinw, e^1/2cosw, u1, u2]\n",
    "VARYP = np.array([1,0,1,1,1,1,1,0,0],dtype='bool')\n",
    "\n",
    "# Method to use when fitting TTVs -- 'linear', or 'slide'\n",
    "TTV_METHOD = 'slide'\n",
    "\n",
    "# directory in which to place MAST downloads\n",
    "DOWNLOAD_DIR = '/Users/research/Desktop/dinosaur/pterodactyl/MAST_downloads/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data from CKS/Kepler DR25/Gaia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in CKS data\n"
     ]
    }
   ],
   "source": [
    "# READ IN THE DATA FROM CSV FILE\n",
    "print('reading in CKS data')\n",
    "\n",
    "# make a target name lightkurve and MAST can understand\n",
    "MAST_TARGET = 'KOI-'+ str(int(TARGET[1:]))\n",
    "\n",
    "# read in a csv file containing info on targets\n",
    "csv_keys, csv_values = wings.read_csv_file(CSV_FILE)\n",
    "\n",
    "# put these csv data into a dictionary\n",
    "target_dict = {}\n",
    "for k in csv_keys: \n",
    "    target_dict[k] = wings.get_csv_data(k,csv_keys,csv_values)\n",
    "\n",
    "# pull relevant quantities and establish GLOBAL variables\n",
    "use = np.array(target_dict['id_starname']) == TARGET\n",
    "\n",
    "NPL    = np.array(target_dict['koi_count'], dtype='int')[use]\n",
    "RSTAR  = np.array(target_dict['iso_srad'],  dtype='float')[use]\n",
    "MSTAR  = np.array(target_dict['iso_smass'], dtype='float')[use]\n",
    "U1     = np.array(target_dict['exo_quadld_u1'], dtype='float')[use]\n",
    "U2     = np.array(target_dict['exo_quadld_u2'], dtype='float')[use]\n",
    "\n",
    "PERIODS = np.array(target_dict['koi_period'], dtype='float')[use]\n",
    "EPOCHS  = np.array(target_dict['koi_time0'],  dtype='float')[use] - 2454833.0  # BKJD = BJD - 2454833 (K-10)\n",
    "RADII   = np.array(target_dict['koi_prad'], dtype='float')[use]\n",
    "\n",
    "# do some consistency checks\n",
    "if all(n == NPL[0] for n in NPL): NPL = NPL[0]\n",
    "else: raise ValueError('There are inconsistencies with NPL in the csv input file')\n",
    "\n",
    "if all(r == RSTAR[0] for r in RSTAR): RSTAR = RSTAR[0]\n",
    "else: raise ValueError('There are inconsistencies with RSTAR in the csv input file')\n",
    "\n",
    "if all(m == MSTAR[0] for m in MSTAR): MSTAR = MSTAR[0]\n",
    "else: raise ValueError('There are inconsistencies with MSTAR in the csv input file')\n",
    "\n",
    "if all(u == U1[0] for u in U1): U1 = U1[0]\n",
    "else: raise ValueError('There are inconsistencies with U1 in the csv input file')\n",
    "\n",
    "if all(u == U2[0] for u in U2): U2 = U2[0]\n",
    "else: raise ValueError('There are inconsistencies with U2 in the csv input file')\n",
    "\n",
    "# combine limb darkening coefficients\n",
    "UCOEFFS = [U1, U2]\n",
    "\n",
    "# put epochs in range (0,period)\n",
    "for npl in range(NPL):\n",
    "    EPOCHS[npl] = EPOCHS[npl] % PERIODS[npl]\n",
    "    \n",
    "# convert radii to units of stellar radius\n",
    "RADII = RADII / RSRE * RSTAR\n",
    "    \n",
    "# THIS NEEDS TO BE UPDATED TO READ IN FROM CSV FILE\n",
    "TTV_METHOD = np.repeat(TTV_METHOD, NPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Planet objects\n",
    "print('initializing %d planet objects' %NPL)\n",
    "\n",
    "planets = []\n",
    "for npl in range(NPL):\n",
    "    p = wings.Planet()\n",
    "    \n",
    "    # put in some basic transit parameters\n",
    "    p.period   = PERIODS[npl]\n",
    "    p.epoch    = EPOCHS[npl]\n",
    "    p.depth    = RADII[npl]**2\n",
    "    p.duration = 13. * (p.period/365.24)**(1./3) * (MSTAR/RSTAR**3)**(-1./3) / 24.\n",
    "    \n",
    "    # estimate transit times from linear ephemeris\n",
    "    p.tts = np.arange(p.epoch, 1600., p.period)\n",
    "    \n",
    "    # make transit indexes\n",
    "    p.index = np.array(np.round((p.tts-p.epoch)/p.period),dtype='int')\n",
    "    \n",
    "    # define which ttv method to use\n",
    "    p.ttv_method = TTV_METHOD[npl]\n",
    "    \n",
    "    planets.append(p)\n",
    "\n",
    "\n",
    "# put planets in order by period\n",
    "planets = wings.sort_by_period(planets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and detrend lightcurves from MAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download long cadence (LC) data\n",
    "print('downloading long cadence data from MAST')\n",
    "lc_rawdata_list = wings.download_lkf(MAST_TARGET, qstart=QSTART, qend=QEND, download_dir=DOWNLOAD_DIR)\n",
    "\n",
    "# clean up LC data\n",
    "QLIST = []\n",
    "for q in range(NQ):\n",
    "    if lc_rawdata_list[q] != None:\n",
    "        QLIST.append(q)\n",
    "        \n",
    "NQ = len(QLIST) \n",
    "lc_rawdata_list = list(filter(None,lc_rawdata_list))\n",
    "\n",
    "\n",
    "# download short cadence (SC) data -- appending to a list avoids errors with files not closing properly\n",
    "print('downloading short cadence data from MAST')\n",
    "\n",
    "sc_rawdata_list = []\n",
    "sc_rawdata_list.append(lk.search_lightcurvefile(MAST_TARGET, cadence='short', mission='Kepler')\\\n",
    "                       .download_all(download_dir=DOWNLOAD_DIR))\n",
    "sc_rawdata_list = sc_rawdata_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make masks of expected transit times\n",
    "print('making transit masks')\n",
    "\n",
    "lc_mask_list = []\n",
    "for q in range(NQ):\n",
    "    qtime = lc_rawdata_list[q].PDCSAP_FLUX.time\n",
    "    qmask = np.zeros_like(qtime, dtype='bool')\n",
    "    \n",
    "    for npl in range(NPL):\n",
    "        qmask += wings.make_transitmask(planets[npl], qtime, masksize=1.5)\n",
    "        \n",
    "    lc_mask_list.append(qmask)\n",
    "    \n",
    "sc_mask_list = []\n",
    "for i in range(len(sc_rawdata_list)):\n",
    "    stime = sc_rawdata_list[i].PDCSAP_FLUX.time\n",
    "    smask = np.zeros_like(stime, dtype='bool')\n",
    "    \n",
    "    for npl in range(NPL):\n",
    "        smask += wings.make_transitmask(planets[npl], stime, masksize=1.5)\n",
    "        \n",
    "    sc_mask_list.append(smask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detrend long cadence data\n",
    "print('detrending long cadence data')\n",
    "lc_pdcsap = wings.detrend_and_join(lc_rawdata_list, masklist=lc_mask_list)\n",
    "lc_pdcsap.scatter()\n",
    "\n",
    "lc_time  = lc_pdcsap.time\n",
    "lc_flux  = lc_pdcsap.flux\n",
    "lc_error = lc_pdcsap.flux_err\n",
    "\n",
    "\n",
    "# detrend short cadence data (don't plot with lk.scatter -- there's too much data!)\n",
    "print('detrending short cadence data')\n",
    "sc_pdcsap = wings.detrend_and_join(sc_rawdata_list, window_length=3001, break_tolerance=750, masklist=sc_mask_list)\n",
    "\n",
    "sc_time  = sc_pdcsap.time\n",
    "sc_flux  = sc_pdcsap.flux\n",
    "sc_error = sc_pdcsap.flux_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove some manually identified bad cadences in pre-specified ranges\n",
    "print('removing pre-identified bad cadences')\n",
    "\n",
    "lc_manual_mask = np.zeros_like(lc_time, dtype='bool')\n",
    "sc_manual_mask = np.zeros_like(sc_time, dtype='bool')\n",
    "\n",
    "if BAD_CADENCES is not None:\n",
    "    for bc in BAD_CADENCES:\n",
    "        lc_manual_mask += (lc_time > bc[0])*(lc_time<bc[1])\n",
    "        sc_manual_mask += (sc_time > bc[0])*(sc_time<bc[1])\n",
    "\n",
    "# long cadence\n",
    "lc_time  = lc_time[~lc_manual_mask]\n",
    "lc_flux  = lc_flux[~lc_manual_mask]\n",
    "lc_error = lc_error[~lc_manual_mask]\n",
    "\n",
    "# short cadence\n",
    "sc_time  = sc_time[~sc_manual_mask]\n",
    "sc_flux  = sc_flux[~sc_manual_mask]\n",
    "sc_error = sc_error[~sc_manual_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make individual masks for where each planet transits\n",
    "print('making transit masks')\n",
    "\n",
    "lc_mask = np.zeros((NPL,len(lc_time)),dtype='bool')\n",
    "sc_mask = np.zeros((NPL,len(sc_time)),dtype='bool')\n",
    "\n",
    "for npl, p in enumerate(planets):\n",
    "    lc_mask[npl] = wings.make_transitmask(p, lc_time, masksize=1.5)\n",
    "    sc_mask[npl] = wings.make_transitmask(p, sc_time, masksize=1.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut stamps around each transit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cut stamps\n",
    "print('cutting stamps')\n",
    "\n",
    "for npl, p in enumerate(planets):\n",
    "    print('\\nPLANET %d, P = %.2f' %(npl+1,p.period))\n",
    "    # make some masks\n",
    "    thisplanet  = np.arange(NPL) == npl\n",
    "    otherplanet = np.arange(NPL) != npl\n",
    "    \n",
    "    lc_selfmask = np.squeeze(lc_mask[thisplanet])\n",
    "    sc_selfmask = np.squeeze(sc_mask[thisplanet])\n",
    "    \n",
    "    lc_siblingmask = np.sum(lc_mask[otherplanet],axis=0,dtype='bool')\n",
    "    sc_siblingmask = np.sum(sc_mask[otherplanet],axis=0,dtype='bool')\n",
    "        \n",
    "    # cut long cadence stamps\n",
    "    lc_time_stamps  = wings.cut_stamps(p, lc_time, lc_time)\n",
    "    lc_flux_stamps  = wings.cut_stamps(p, lc_time, lc_flux)\n",
    "    lc_error_stamps = wings.cut_stamps(p, lc_time, lc_error)\n",
    "    lc_mask_stamps  = wings.cut_stamps(p, lc_time, lc_siblingmask)\n",
    "    \n",
    "    # cut short cadence stamps\n",
    "    sc_time_stamps  = wings.cut_stamps(p, sc_time, sc_time)\n",
    "    sc_flux_stamps  = wings.cut_stamps(p, sc_time, sc_flux)\n",
    "    sc_error_stamps = wings.cut_stamps(p, sc_time, sc_error)\n",
    "    sc_mask_stamps  = wings.cut_stamps(p, sc_time, sc_siblingmask)\n",
    "    \n",
    "    # combine SC and LC stamps\n",
    "    p.time_stamps,  t_cadence = wings.combine_stamps(sc_time_stamps,  lc_time_stamps)\n",
    "    p.flux_stamps,  f_cadence = wings.combine_stamps(sc_flux_stamps,  lc_flux_stamps)\n",
    "    p.error_stamps, e_cadence = wings.combine_stamps(sc_error_stamps, lc_error_stamps)\n",
    "    p.mask_stamps,  m_cadence = wings.combine_stamps(sc_mask_stamps,  lc_mask_stamps)\n",
    "    \n",
    "    checkf = np.array_equal(t_cadence, f_cadence)\n",
    "    checke = np.array_equal(t_cadence, e_cadence)\n",
    "    checkm = np.array_equal(t_cadence, m_cadence)\n",
    "    \n",
    "    if (checkf+checke+checkm) == False:\n",
    "        raise ValueError('recovered stamp types do not all match')\n",
    "    else:\n",
    "        p.stamp_cadence = t_cadence\n",
    "\n",
    "    # clean up the stamps\n",
    "    wings.mask_overlapping_transits(p)\n",
    "    wings.clip_outlier_cadences(p)\n",
    "    wings.flatten_stamps(p)\n",
    "    \n",
    "    # pick out the good stamps\n",
    "    p.calculate_stamp_coverage()    \n",
    "    p.identify_good_transits(cover_fraction=0.7, chisq_sigma=20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display a few long cadence stamps\n",
    "print('LONG CADENCE TRANSITS')\n",
    "fig, axes = plt.subplots(1, NPL, figsize=(16,8))\n",
    "\n",
    "for npl, p in enumerate(planets):\n",
    "    lcts = p.grab_stamps('time', 'long')\n",
    "    lcfs = p.grab_stamps('flux', 'long')\n",
    "    \n",
    "    tts = p.tts[p.quality*(p.stamp_cadence=='long')]\n",
    "    \n",
    "    ax = axes[npl]\n",
    "    for i in range(np.min([10,len(lcts)])):\n",
    "        ax.plot(lcts[i]-tts[i], lcfs[i]-p.depth*2*i, '.')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a few short cadence stamps\n",
    "print('SHORT CADENCE TRANSITS')\n",
    "fig, axes = plt.subplots(1, NPL, figsize=(16,16))\n",
    "\n",
    "for npl, p in enumerate(planets):\n",
    "    scts = p.grab_stamps('time', 'short')\n",
    "    scfs = p.grab_stamps('flux', 'short')\n",
    "    \n",
    "    tts = p.tts[p.quality*(p.stamp_cadence=='short')]\n",
    "    \n",
    "    ax = axes[npl]\n",
    "    for i in range(np.min([10,len(scts)])):\n",
    "        ax.plot(scts[i]-tts[i], scfs[i]-p.depth*5*i, '.')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate correlated noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make a mask where any planet transits\n",
    "scm = sc_mask.sum(axis=0) > 0\n",
    "\n",
    "# set Npts from 3 x maximum transit duration\n",
    "durations = np.zeros(NPL)\n",
    "for npl, p in enumerate(planets):\n",
    "    durations[npl] = p.duration\n",
    "Npts = int(3*durations.max()*24*3600/SCIT)\n",
    "\n",
    "# generate the autocorrelation function\n",
    "xcor, acor, wcor = wings.generate_acor_fxn(sc_time, sc_flux, scm, Npts)\n",
    "\n",
    "# model the autocorrelation function (don't use lag-zero data)\n",
    "acor_model, acor_theta = wings.model_acor_fxn(xcor[1:], acor[1:], wcor=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get size of longest stamp\n",
    "stamplength = []\n",
    "for npl, p in enumerate(planets):\n",
    "    tstamps = p.grab_stamps('time')\n",
    "    \n",
    "    for ts in tstamps:\n",
    "        stamplength.append(int(np.round((ts[-1]-ts[0])/(SCIT/3600/24))))\n",
    "        \n",
    "msl = np.max(stamplength) + 1\n",
    "\n",
    "# estimate contribution from red and white noise\n",
    "sigma_white = np.median(sc_error)\n",
    "sigma_tot   = np.std(sc_flux[~scm])\n",
    "sigma_red   = np.sqrt(sigma_tot**2 - sigma_white**2)\n",
    "\n",
    "print(sigma_red**2/sigma_tot**2)\n",
    "print(np.sqrt(np.sum(acor[1:]**2)/acor[0]**2))\n",
    "print(np.sqrt(acor[1]/acor[0]))\n",
    "\n",
    "# make the covariance matrix\n",
    "covmatrix = wings.make_covariance_matrix(xcor[1:], acor_theta, msl, sigma_white, sigma_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for npl, p in enumerate(planets):\n",
    "    N = len(p.tts)\n",
    "    \n",
    "    icov = []\n",
    "    for i in range(N):\n",
    "        if p.quality[i] == False:\n",
    "            icov.append(None)\n",
    "        else:\n",
    "            cadence = p.stamp_cadence[i]\n",
    "            tstamp  = p.time_stamps[i]\n",
    "            estamp  = p.error_stamps[i]\n",
    "            \n",
    "            if cadence == 'short':\n",
    "                x = np.array(np.round((tstamp-tstamp[0])/(SCIT/3600/24)),dtype='int')\n",
    "                cm_here = covmatrix[x,:]\n",
    "                cm_here = cm_here[:,x]\n",
    "                icov.append(np.linalg.inv(cm_here))\n",
    "            \n",
    "            elif cadence == 'long':\n",
    "                cm_here = np.diag(np.ones(len(estamp))*np.median(estamp)**2)\n",
    "                icov.append(np.linalg.inv(cm_here))\n",
    "                \n",
    "    p.icov = icov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First iteration of chisq minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize parameter vectors for each planet\n",
    "for npl, p in enumerate(planets):\n",
    "    # set up shape parameter vectors\n",
    "    p.pshape = np.array([p.epoch, p.period, np.sqrt(p.depth), 1/p.duration, 0.25, 0.0355, 0.0355, U1, U2])\n",
    "    \n",
    "    # define ttv model\n",
    "    p.ptime = np.array([p.epoch,p.period])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imp.reload(wings)\n",
    "\n",
    "# run a Levenberg-Marquardt minimization\n",
    "print('running Levenberg-Marquardt minimization')\n",
    "\n",
    "LMstartingtime = timeit.default_timer()\n",
    "\n",
    "# turn off RuntimeWarnings -- these can be annoying during LM fits\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "\n",
    "# iterate over each planet\n",
    "for npl, p in enumerate(planets):\n",
    "    print('\\n\\nPLANET %d, P = %.2f' %(npl+1,p.period))\n",
    "    \n",
    "    # do the first LM fit\n",
    "    print('iteration', 1)\n",
    "    p, X2_shape, X2_time = wings.do_LM_fit(p, RSTAR, VARYP, TTV_METHOD[npl], verbose=False, do_plots=False)\n",
    "    \n",
    "    # update transit times to smooth interpolated values\n",
    "    p.tts = wings.do_ttv_lombscargle_analysis(p)[0]\n",
    "\n",
    "    # now iterate until convergence\n",
    "    loop = True\n",
    "    iterations = 1\n",
    "    while loop:\n",
    "        iterations += 1\n",
    "        print('iteration', iterations)\n",
    "        \n",
    "        planet, X2_shape_new, X2_time_new = wings.do_LM_fit(p, RSTAR, VARYP, TTV_METHOD[npl])\n",
    "\n",
    "        shape_converged = np.abs(X2_shape-X2_shape_new)/X2_shape < 0.01\n",
    "        time_converged  = np.abs(X2_time-X2_time_new)/X2_time < 0.01\n",
    "        \n",
    "        if shape_converged*time_converged:\n",
    "            loop = False\n",
    "        else:\n",
    "            p.tts = wings.do_ttv_lombscargle_analysis(p)[0]\n",
    "            X2_shape = X2_shape_new.copy()\n",
    "            X2_time  = X2_time_new.copy()\n",
    "            \n",
    "        \n",
    "        if iterations >= 10:\n",
    "            raise Exception('LM minimization has not converged after 10 iterations')\n",
    "    \n",
    "    # reduced chi-sq\n",
    "    X2u = X2_shape_new/(len(np.hstack(p.grab_stamps('time')))-np.sum(VARYP)-len(p.ptime))\n",
    "\n",
    "    # print results and plot the lightcurve\n",
    "    print('   {X2u = %.2f}' %X2u)    \n",
    "    fig = p.plot_folded_lightcurve()\n",
    "    \n",
    "    # flag transits with high chisq\n",
    "    p.identify_good_transits(cover_fraction=0.7, chisq_sigma=5.0, verbose=False)\n",
    "    \n",
    "    \n",
    "# turn warnings back on\n",
    "warnings.resetwarnings()\n",
    "\n",
    "LMendingtime = timeit.default_timer()\n",
    "print('LM fitting runtime = %.2f min' %((LMendingtime-LMstartingtime)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(wings)\n",
    "\n",
    "p = planets[2]\n",
    "tts = p.tts[p.quality]\n",
    "time_stamps = p.grab_stamps('time')\n",
    "flux_stamps = p.grab_stamps('flux')\n",
    "cadences = p.stamp_cadence[p.quality]\n",
    "\n",
    "model_stamps = wings.calculate_model_flux(p.pshape, RSTAR, tts, time_stamps, cadences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(time_stamps)):\n",
    "    plt.figure()\n",
    "    plt.plot(time_stamps[i], flux_stamps[i], 'ko', fillstyle='none')\n",
    "    plt.plot(time_stamps[i], model_stamps[i], 'orange', lw=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npl, p in enumerate(planets):\n",
    "    print('\\n\\nPLANET %d, P = %.2f' %(npl+1,p.period))\n",
    "    wings.pshape_values(p, Rstar=RSTAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some TTV analysis routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(wings)\n",
    "\n",
    "for npl, p in enumerate(planets):\n",
    "    print('\\n\\nPLANET %d, P = %.2f days' %(npl+1,p.period))\n",
    "    \n",
    "    tts_new, peak_freq, peak_fap = wings.do_ttv_lombscargle_analysis(p, verbose=True, do_plots=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
