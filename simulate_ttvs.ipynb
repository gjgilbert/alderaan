{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy.polynomial.polynomial as poly\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import importlib as imp\n",
    "from   timeit import default_timer as timer\n",
    "import rebound\n",
    "\n",
    "import alderaan.io as io\n",
    "from alderaan.constants import *\n",
    "from alderaan.utils import *\n",
    "\n",
    "global_start_time = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIMARY_DIR  = '/Users/research/projects/alderaan/'\n",
    "CSV_FILE = PRIMARY_DIR + \"Catalogs/simulated_catalog_radius_valley.csv\"\n",
    "SIM_DIR  = PRIMARY_DIR + \"Simulations/TTVs/\"\n",
    "\n",
    "# check if all the paths exist and create them if not\n",
    "if os.path.exists(SIM_DIR) == False:\n",
    "    os.mkdir(SIM_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data from csv file\n",
      "Loaded 636 real KOIs\n"
     ]
    }
   ],
   "source": [
    "# Read in the data from csv file\n",
    "print('Reading in data from csv file')\n",
    "\n",
    "# read in a csv file containing info on targets\n",
    "csv_keys, csv_values = io.read_csv_file(CSV_FILE)\n",
    "\n",
    "# put these csv data into a dictionary\n",
    "catalog = {}\n",
    "for k in csv_keys: \n",
    "    catalog[k] = io.get_csv_data(k, csv_keys, csv_values)\n",
    "    \n",
    "k0 = \"koi_id\"\n",
    "    \n",
    "print(\"Loaded {0} real KOIs\".format(len(catalog[k0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datatypes\n",
    "for k in catalog.keys():\n",
    "    try:\n",
    "        catalog[k] = np.asarray(catalog[k], dtype=\"float\")\n",
    "    except:\n",
    "        catalog[k] = np.asarray(catalog[k])\n",
    "    \n",
    "    \n",
    "catalog[\"npl\"] = np.asarray(catalog[\"npl\"], dtype=\"int\")\n",
    "catalog[\"kic_id\"] = np.asarray(catalog[\"kic_id\"], dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_START = 0.\n",
    "TIME_END = 1600.\n",
    "\n",
    "# put all epochs in range (TIME_START, period)\n",
    "\n",
    "for i, koi in enumerate(catalog[\"koi_id\"]):\n",
    "    while(catalog[\"epoch\"][i] > TIME_START):\n",
    "        catalog[\"epoch\"][i] -= catalog[\"period\"][i]\n",
    "\n",
    "    catalog[\"epoch\"][i] += catalog[\"period\"][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric TTVs\n",
    "### Single planet systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, koi in enumerate(catalog[\"koi_id\"]):\n",
    "    #print(i, koi, catalog[\"ttv_type\"][i])\n",
    "    ephemeris = np.arange(catalog[\"epoch\"][i], TIME_END, catalog[\"period\"][i])\n",
    "    inds = np.arange(len(ephemeris))\n",
    "        \n",
    "    \n",
    "    # linear ttvs\n",
    "    if catalog[\"ttv_type\"][i] == \"linear\":\n",
    "        omc = np.zeros_like(ephemeris)\n",
    "        tts = ephemeris + omc\n",
    "        \n",
    "        \n",
    "    # quadratic ttvs\n",
    "    if catalog[\"ttv_type\"][i] == \"quadratic\":\n",
    "        x = 2*(ephemeris-TIME_START)/(TIME_END-TIME_START) - 1\n",
    "        Leg2 = 0.5*(3*x**2 - 1)\n",
    "        \n",
    "        scale = np.random.choice([0.1/24, catalog[\"duration\"][i]/24/3])\n",
    "        C2 = np.random.normal(loc=0, scale=scale)\n",
    "        \n",
    "        omc = C2*Leg2\n",
    "        tts = ephemeris + omc\n",
    "        \n",
    "        \n",
    "    # cubic ttvs\n",
    "    if catalog[\"ttv_type\"][i] == \"cubic\":\n",
    "        x = 2*(ephemeris-TIME_START)/(TIME_END-TIME_START) - 1\n",
    "        \n",
    "        Leg2 = 0.5*(3*x**2 - 1)\n",
    "        Leg3 = 0.5*(5*x**3 - 3*x)\n",
    "        \n",
    "        scale = np.random.choice([0.1/24, catalog[\"duration\"][i]/24/3])\n",
    "        C2, C3  = np.random.normal(loc=0, scale=scale, size=2)\n",
    "        \n",
    "        omc = C2*Leg2 + C3*Leg3\n",
    "        tts = ephemeris + omc\n",
    "        \n",
    "        \n",
    "    # sinusoidal ttvs\n",
    "    if catalog[\"ttv_type\"][i] == \"sinusoidal\":\n",
    "        fmin = 2/(TIME_END - TIME_START)\n",
    "        fmax = 1/(4*catalog[\"period\"][i])\n",
    "        logf = np.random.uniform(np.log(fmin), np.log(fmax))\n",
    "        \n",
    "        scale = np.random.choice([0.1/24, catalog[\"duration\"][i]/24/3])\n",
    "        A, B  = np.random.normal(loc=0, scale=scale, size=2)\n",
    "\n",
    "        f = np.exp(logf)\n",
    "        t = np.copy(ephemeris)\n",
    "        \n",
    "        omc = A*np.sin(2*pi*f*t) + B*np.cos(2*pi*f*t)\n",
    "        tts = ephemeris + omc        \n",
    "    \n",
    "    \n",
    "    # gaussian (white noise) ttvs\n",
    "    if catalog[\"ttv_type\"][i] == \"gaussian\":\n",
    "        scale = np.random.choice([0.1/24, catalog[\"duration\"][i]/24/3])\n",
    "        \n",
    "        omc = np.random.normal(loc=0, scale=scale, size=len(ephemeris))\n",
    "        tts = ephemeris + omc\n",
    "        \n",
    "        \n",
    "    # no ttv perturbations\n",
    "    if catalog[\"ttv_type\"][i] == \"none\":\n",
    "        omc = np.zeros_like(ephemeris)\n",
    "        tts = ephemeris + omc\n",
    "    \n",
    "    \n",
    "    # save the results\n",
    "    if (catalog[\"npl\"][i] == 1):\n",
    "        data_out  = np.vstack([inds, tts]).swapaxes(0,1)\n",
    "        fname_out = SIM_DIR + \"S\" + koi[1:] + '_00_sim_ttvs.txt'\n",
    "\n",
    "        np.savetxt(fname_out, data_out, fmt=('%1d', '%.8f'), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-planet systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentric_doubles = np.unique(catalog[\"koi_id\"][catalog[\"ttv_type\"] == \"none\"])\n",
    "\n",
    "ecc_new = []\n",
    "omega_new = []\n",
    "\n",
    "for i, koi in enumerate(eccentric_doubles):\n",
    "    use = catalog[\"koi_id\"] == koi\n",
    "    npl = catalog[\"npl\"][use][0]\n",
    "    \n",
    "    per = catalog[\"period\"][use]\n",
    "    t0 = catalog[\"epoch\"][use]\n",
    "    \n",
    "    for j in range(npl):\n",
    "        ephemeris = np.arange(t0[j], TIME_END, per[j])\n",
    "        inds = np.arange(len(ephemeris))\n",
    "    \n",
    "        data_out  = np.vstack([inds, ephemeris]).swapaxes(0,1)\n",
    "        fname_out = SIM_DIR + \"S\" + koi[1:] + '_{:02d}'.format(j) + '_sim_ttvs.txt'\n",
    "\n",
    "        np.savetxt(fname_out, data_out, fmt=('%1d', '%.8f'), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-body simulations with REBOUND\n",
    "### Multiplanet systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(Mstar, mass, per, ecc, omega, mean_anomaly):\n",
    "    \"\"\"\n",
    "    Docstring\n",
    "    \"\"\"\n",
    "    \n",
    "    NPL = len(mass)\n",
    "    sma = get_sma(per, Mstar)*RSAU\n",
    "    \n",
    "    \n",
    "    # set up simulation\n",
    "    sim = rebound.Simulation()\n",
    "    sim.units = (\"AU\", \"Msun\", \"days\")\n",
    "    sim.add(m=Mstar)\n",
    "\n",
    "    for npl in range(NPL):\n",
    "        sim.add(m=mass[npl], a=sma[npl], e=ecc[npl], omega=omega[npl], M=mean_anomaly[npl])\n",
    "\n",
    "    p = sim.particles\n",
    "    \n",
    "                                                                 \n",
    "    # do the integration\n",
    "    transit_times = []\n",
    "\n",
    "    for npl in range(NPL):\n",
    "        transit_times.append([])\n",
    "\n",
    "        while sim.t < 1600:\n",
    "            y_old = p[npl+1].y - p[0].y\n",
    "\n",
    "            t_old = sim.t\n",
    "            sim.integrate(sim.t + per.min()/20)\n",
    "            t_new = sim.t\n",
    "\n",
    "            # sign of y changes and planet is in front of star (x > 0)\n",
    "            if y_old*(p[npl+1].y-p[0].y) < 0 and p[npl+1].x-p[0].x > 0:\n",
    "\n",
    "                # bisect until precision is reached\n",
    "                while t_new-t_old > 1e-7:\n",
    "                    if y_old*(p[npl+1].y-p[0].y) < 0:\n",
    "                        t_new = sim.t\n",
    "                    else:\n",
    "                        t_old = sim.t\n",
    "                    sim.integrate( (t_new+t_old)/2)\n",
    "\n",
    "                transit_times[npl].append(sim.t)\n",
    "\n",
    "               # integrate 0.05 to be past the transit        \n",
    "                sim.integrate(sim.t + per.min()/20)\n",
    "\n",
    "        sim.integrate(0.)\n",
    "        \n",
    "    return transit_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rebound_systems = np.unique(catalog[\"koi_id\"][catalog[\"ttv_type\"] == \"rebound\"])\n",
    "\n",
    "ecc_new = []\n",
    "omega_new = []\n",
    "\n",
    "for i, koi in enumerate(rebound_systems):\n",
    "    print(i, koi)\n",
    "    \n",
    "    # get parameters from simulated catalog\n",
    "    use = catalog[\"koi_id\"] == koi\n",
    "    \n",
    "    npl    = catalog[\"npl\"][use][0]\n",
    "    Mstar  = catalog[\"mstar\"][use][0]\n",
    "    mass   = catalog[\"pmass\"][use]/MSME\n",
    "    per    = catalog[\"period\"][use]\n",
    "    M_anom = np.random.uniform(0, 2*pi, npl)\n",
    "    \n",
    "    \n",
    "    # draw eccentricity vectors (see Lithwick, Xie, & Wu 2012)\n",
    "    ecc = np.ones(npl)\n",
    "    while np.any(ecc > 0.4):\n",
    "        esinw, ecosw = np.random.normal(loc=0, scale=0.008, size=2*npl).reshape((2,npl))\n",
    "\n",
    "        ecc = np.sqrt(esinw**2 + ecosw**2)\n",
    "        omega = np.arctan2(esinw, ecosw)\n",
    "    \n",
    "    \n",
    "    for e0 in ecc:\n",
    "        ecc_new.append(e0)\n",
    "    for w0 in omega:\n",
    "        omega_new.append(w0)\n",
    "        \n",
    "    \n",
    "    # integrate REBOUND to get transit times\n",
    "    transit_times = run_simulation(Mstar, mass, per, ecc, omega, M_anom)    \n",
    "    \n",
    "    transit_inds  = []\n",
    "    for j in range(npl):\n",
    "        transit_inds.append(np.arange(len(transit_times[j])))\n",
    "        \n",
    "        \n",
    "    # save the results\n",
    "    for j in range(npl):\n",
    "        data_out  = np.vstack([transit_inds[j], transit_times[j]]).swapaxes(0,1)\n",
    "        fname_out = SIM_DIR + \"S\" + koi[1:] + '_{:02d}'.format(j) + '_sim_ttvs.txt'\n",
    "\n",
    "        np.savetxt(fname_out, data_out, fmt=('%1d', '%.8f'), delimiter='\\t')\n",
    "        \n",
    "\n",
    "# update eccentricity vectors in the catalog\n",
    "replace = catalog[\"ttv_type\"] == \"rebound\"\n",
    "\n",
    "catalog[\"ecc\"][replace] = ecc_new\n",
    "catalog[\"omega\"][replace] = omega_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update periods and epochs to least squares fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_lsq = []\n",
    "period_lsq = []\n",
    "\n",
    "\n",
    "for i, koi in enumerate(catalog[\"koi_id\"]):\n",
    "    use = catalog[\"koi_id\"] == koi\n",
    "    npl = np.sum(use)\n",
    "    \n",
    "    # this if statement avoids double counting multiplant systems\n",
    "    if len(period_lsq) <= i:\n",
    "        for j in range(npl):\n",
    "            data_in = np.loadtxt(SIM_DIR + \"S\" + koi[1:] + '_{:02d}'.format(j) + '_sim_ttvs.txt')\n",
    "            inds, tts = np.atleast_2d(data_in).swapaxes(0,1)\n",
    "\n",
    "            if len(tts) > 1:\n",
    "                pfit = poly.polyfit(inds, tts, 1)\n",
    "\n",
    "                epoch_lsq.append(pfit[0])\n",
    "                period_lsq.append(pfit[1])\n",
    "\n",
    "            else:\n",
    "                epoch_lsq.append(tts[0])\n",
    "                period_lsq.append(catalog[\"period\"][use][j])\n",
    "                \n",
    "\n",
    "catalog[\"epoch\"] = np.asarray(epoch_lsq)\n",
    "catalog[\"period\"] = np.asarray(period_lsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update transit durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculate transit durations\n",
    "sma = get_sma(catalog[\"period\"], catalog[\"mstar\"])\n",
    "\n",
    "catalog[\"duration\"] = 24*get_dur_tot(catalog[\"period\"], \n",
    "                                     catalog[\"prad\"]/RSRE, \n",
    "                                     catalog[\"rstar\"],\n",
    "                                     catalog[\"impact\"],\n",
    "                                     sma,\n",
    "                                     catalog[\"ecc\"],\n",
    "                                     catalog[\"omega\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do some cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = list(catalog.keys())\n",
    "int_keys = ['kic_id', 'npl', 'depth']\n",
    "string_keys = ['planet_name', 'disposition', 'koi_id', 'ttv_type']\n",
    "precise_keys = ['period', 'epoch']\n",
    "\n",
    "\n",
    "for k in catalog.keys():\n",
    "    if np.isin(k, int_keys):\n",
    "        catalog[k] = np.array(catalog[k], dtype=\"int\")\n",
    "    elif np.isin(k, string_keys):\n",
    "        catalog[k] = catalog[k]\n",
    "    elif np.isin(k, precise_keys):\n",
    "        catalog[k] = np.round(np.array(catalog[k], dtype=\"float\"), 5)\n",
    "    else:\n",
    "        catalog[k] = np.round(np.array(catalog[k], dtype=\"float\"), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITENEW = True\n",
    "if WRITENEW:\n",
    "    with open(CSV_FILE, \"w\") as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(catalog.keys())\n",
    "        writer.writerows(zip(*catalog.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL RUNTIME = 0.04 min\n"
     ]
    }
   ],
   "source": [
    "print('TOTAL RUNTIME = %.2f min' %((timer()-global_start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
