{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT STATEMENTS AND PRELIMINARIES\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from   scipy import stats\n",
    "from   alderaan.constants import *\n",
    "\n",
    "MAINPATH = '/Users/research/projects/alderaan/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in exoplanet archive cumulative KOI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file names\n",
    "csv_file = MAINPATH + 'Catalogs/cumulative_20210416.csv'\n",
    "\n",
    "# convenience function to read in csv file\n",
    "def read_csv_file(filename):\n",
    "    data = []\n",
    "    with open(filename) as infile:\n",
    "        reader = csv.reader(infile)\n",
    "\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "\n",
    "        keys   = data[75]\n",
    "        values = data[76:]\n",
    "\n",
    "            \n",
    "        return keys, values\n",
    "\n",
    "\n",
    "# READ IN DR25 DATABASE -- https://exoplanetarchive.ipac.caltech.edu\n",
    "arc_keys, arc_data = read_csv_file(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kepid',\n",
       " 'kepoi_name',\n",
       " 'kepler_name',\n",
       " 'koi_disposition',\n",
       " 'koi_vet_date',\n",
       " 'koi_pdisposition',\n",
       " 'koi_score',\n",
       " 'koi_fpflag_nt',\n",
       " 'koi_fpflag_ss',\n",
       " 'koi_fpflag_co',\n",
       " 'koi_fpflag_ec',\n",
       " 'koi_period',\n",
       " 'koi_period_err1',\n",
       " 'koi_period_err2',\n",
       " 'koi_time0bk',\n",
       " 'koi_time0bk_err1',\n",
       " 'koi_time0bk_err2',\n",
       " 'koi_impact',\n",
       " 'koi_impact_err1',\n",
       " 'koi_impact_err2',\n",
       " 'koi_duration',\n",
       " 'koi_duration_err1',\n",
       " 'koi_duration_err2',\n",
       " 'koi_depth',\n",
       " 'koi_depth_err1',\n",
       " 'koi_depth_err2',\n",
       " 'koi_ror',\n",
       " 'koi_ror_err1',\n",
       " 'koi_ror_err2',\n",
       " 'koi_srho',\n",
       " 'koi_srho_err1',\n",
       " 'koi_srho_err2',\n",
       " 'koi_prad',\n",
       " 'koi_prad_err1',\n",
       " 'koi_prad_err2',\n",
       " 'koi_teq',\n",
       " 'koi_teq_err1',\n",
       " 'koi_teq_err2',\n",
       " 'koi_insol',\n",
       " 'koi_insol_err1',\n",
       " 'koi_insol_err2',\n",
       " 'koi_dor',\n",
       " 'koi_dor_err1',\n",
       " 'koi_dor_err2',\n",
       " 'koi_ldm_coeff2',\n",
       " 'koi_ldm_coeff1',\n",
       " 'koi_model_snr',\n",
       " 'koi_count',\n",
       " 'koi_num_transits',\n",
       " 'koi_tce_plnt_num',\n",
       " 'koi_tce_delivname',\n",
       " 'koi_steff',\n",
       " 'koi_steff_err1',\n",
       " 'koi_steff_err2',\n",
       " 'koi_slogg',\n",
       " 'koi_slogg_err1',\n",
       " 'koi_slogg_err2',\n",
       " 'koi_smet',\n",
       " 'koi_smet_err1',\n",
       " 'koi_smet_err2',\n",
       " 'koi_srad',\n",
       " 'koi_srad_err1',\n",
       " 'koi_srad_err2',\n",
       " 'koi_smass',\n",
       " 'koi_smass_err1',\n",
       " 'koi_smass_err2',\n",
       " 'ra',\n",
       " 'dec',\n",
       " 'koi_kepmag']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience functions to pull data from csv files\n",
    "def getdata(keyname,keys=arc_keys,data=arc_data):\n",
    "    '''\n",
    "    keyname = (string) of column definition\n",
    "    '''\n",
    "    kid = keys.index(keyname)\n",
    "    \n",
    "    outdata = []\n",
    "    for row in data:\n",
    "        outdata.append(row[kid])\n",
    "    \n",
    "    return outdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read archive data into a dictionary\n",
    "arc = {}\n",
    "for k in arc_keys:\n",
    "    arc[k] = getdata(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of queried DR25 objects = 9564\n"
     ]
    }
   ],
   "source": [
    "def check_lengths(data):\n",
    "    keys = data.keys()\n",
    "    k0   = list(keys)[0]\n",
    "    L0   = len(data[k0])\n",
    "    \n",
    "    for k in keys:\n",
    "        if len(data[k]) != L0:\n",
    "            raise ValueError('inconsistent array lengths')\n",
    "            \n",
    "    return None\n",
    "\n",
    "\n",
    "def convert_to_arrays(data):\n",
    "    keys = data.keys()\n",
    "    dnew = {}\n",
    "    \n",
    "    for k in keys:\n",
    "        dnew[k] = np.asarray(data[k])\n",
    "        \n",
    "    return dnew       \n",
    "\n",
    "\n",
    "\n",
    "# grab a reference key\n",
    "arc_k0 = list(arc.keys())[0]\n",
    "\n",
    "\n",
    "# convert to arrays\n",
    "arc = convert_to_arrays(arc)\n",
    "print('total number of queried DR25 objects =', len(arc[arc_k0]))\n",
    "\n",
    "\n",
    "check_lengths(arc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Gaia DR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaiapath = MAINPATH + \"Catalogs/berger_2020_gaia_kepler_tab2_output.txt\"\n",
    "\n",
    "# read in the stellar output parameters\n",
    "with open(gaiapath, \"r\") as infile:\n",
    "    raw_gaia_data = []\n",
    "    \n",
    "    for i, line in enumerate(infile):\n",
    "        raw_gaia_data.append(line.split(\"&\"))\n",
    "            \n",
    "raw_gaia_data = np.array(raw_gaia_data)\n",
    "\n",
    "\n",
    "# strip off trailing \\newline commands\n",
    "for i in range(len(raw_gaia_data)):\n",
    "    raw_gaia_data[i,-1] = raw_gaia_data[i,-1].strip(\"\\n\").strip(\"\\ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_gaia_dict = {}\n",
    "\n",
    "for i, k in enumerate(raw_gaia_data[0]):\n",
    "    raw_gaia_dict[k] = raw_gaia_data[1:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia = {}\n",
    "\n",
    "gaia['kic']          = raw_gaia_dict['KIC']\n",
    "\n",
    "gaia['Mstar']        = raw_gaia_dict['iso_mass']\n",
    "gaia['Mstar_err1']   = raw_gaia_dict['iso_mass_err1']\n",
    "gaia['Mstar_err2']   = raw_gaia_dict['iso_mass_err2']\n",
    "\n",
    "gaia['Rstar']        = raw_gaia_dict['iso_rad']\n",
    "gaia['Rstar_err1']   = raw_gaia_dict['iso_rad_err1']\n",
    "gaia['Rstar_err2']   = raw_gaia_dict['iso_rad_err2']\n",
    "\n",
    "gaia['logrho']      = raw_gaia_dict['iso_rho']\n",
    "gaia['logrho_err1'] = raw_gaia_dict['iso_rho_err1']\n",
    "gaia['logrho_err2'] = raw_gaia_dict['iso_rho_err2']\n",
    "\n",
    "gaia['Teff']         = raw_gaia_dict['iso_teff']\n",
    "gaia['Teff_err1']    = raw_gaia_dict['iso_teff_err1']\n",
    "gaia['Teff_err2']    = raw_gaia_dict['iso_teff_err2']\n",
    "\n",
    "gaia['FeH']          = raw_gaia_dict['iso_feh']\n",
    "gaia['FeH_err1']     = raw_gaia_dict['iso_feh_err1']\n",
    "gaia['FeH_err2']     = raw_gaia_dict['iso_feh_err2']\n",
    "\n",
    "gaia['logg']          = raw_gaia_dict['iso_logg']\n",
    "gaia['logg_err1']     = raw_gaia_dict['iso_logg_err1']\n",
    "gaia['logg_err2']     = raw_gaia_dict['iso_logg_err2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove false-positives, low SNR objects, and monotransits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after removing false positives, cumulative archive KOIs = 4724\n"
     ]
    }
   ],
   "source": [
    "# remove false positives from DR25\n",
    "fp = arc['koi_disposition'] == 'FALSE POSITIVE'\n",
    "fp += (arc['koi_disposition'] != 'CONFIRMED')*(arc['koi_pdisposition'] == 'FALSE POSITIVE')\n",
    "\n",
    "for k in arc.keys():\n",
    "    arc[k] = arc[k][~fp]\n",
    "\n",
    "print('after removing false positives, cumulative archive KOIs =', len(arc[arc_k0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after removing unconfirmed objects with SNR < 7.1, KOIs = 4508\n"
     ]
    }
   ],
   "source": [
    "# cut non-confirmed low signal-to-noise objects (SNR < 7.1)\n",
    "arc_snr = arc['koi_model_snr']\n",
    "arc_snr[arc_snr == ''] = 0\n",
    "arc_snr = np.array(arc_snr, dtype='float')\n",
    "\n",
    "disposition = arc['koi_disposition']\n",
    "npl = np.array(arc['koi_count'], dtype=\"int\")\n",
    "\n",
    "for k in arc.keys():\n",
    "    bad = (arc_snr < 7.1)*(disposition != 'CONFIRMED')*(npl < 2)\n",
    "    \n",
    "    arc[k] = arc[k][~bad]\n",
    "    \n",
    "print('after removing unconfirmed objects with SNR < 7.1, KOIs =', len(arc[arc_k0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after removing objects with P > 730 days, KOIs = 4501\n"
     ]
    }
   ],
   "source": [
    "# cut very long period transits (period > 730)\n",
    "arc_per = arc['koi_period']\n",
    "arc_per[arc_per == ''] = 1e6\n",
    "arc_per = np.array(arc_per, dtype='float')\n",
    "\n",
    "npl = np.array(arc['koi_count'], dtype=\"int\")\n",
    "\n",
    "bad = (arc_per > 730)*(npl < 2)\n",
    "\n",
    "for k in arc.keys():\n",
    "    arc[k] = arc[k][~bad]\n",
    "    \n",
    "    \n",
    "print('after removing objects with P > 730 days, KOIs =', len(arc[arc_k0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after removing objects with fewer than three transits, KOIs = 4273\n"
     ]
    }
   ],
   "source": [
    "# remove objects with fewer than three transits\n",
    "arc_num_transits = arc[\"koi_num_transits\"]\n",
    "arc_num_transits[arc_num_transits == ''] = 0\n",
    "arc_num_transits = np.array(arc_num_transits, dtype='int')\n",
    "\n",
    "npl = np.array(arc['koi_count'], dtype=\"int\")\n",
    "\n",
    "bad = (arc_num_transits < 3)*(npl < 2)\n",
    "\n",
    "for k in arc.keys():\n",
    "    arc[k] = arc[k][~bad]\n",
    "\n",
    "print('after removing objects with fewer than three transits, KOIs =', len(arc[arc_k0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize my catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nobj = len(arc['kepid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_catalog = {}\n",
    "\n",
    "my_catalog['planet_name'] = arc['kepoi_name']\n",
    "my_catalog['disposition'] = arc['koi_disposition']\n",
    "\n",
    "my_catalog['koi_id']  = np.array(['K00000']*Nobj)\n",
    "my_catalog['kic_id']  = arc['kepid']\n",
    "\n",
    "my_catalog['npl'] = arc['koi_count']\n",
    "my_catalog['kep_mag'] = np.array(arc['koi_kepmag'], dtype='float').round(3)\n",
    "\n",
    "my_catalog['mstar'] = arc['koi_smass']\n",
    "my_catalog['mstar_err1'] = arc['koi_smass_err1']\n",
    "my_catalog['mstar_err2'] = arc['koi_smass_err2']\n",
    "\n",
    "my_catalog['rstar'] = arc['koi_srad']\n",
    "my_catalog['rstar_err1'] = arc['koi_srad_err1']\n",
    "my_catalog['rstar_err2'] = arc['koi_srad_err2']\n",
    "\n",
    "my_catalog['logrho'] = np.zeros_like(arc['koi_srad'])\n",
    "my_catalog['logrho_err1'] = np.zeros_like(arc['koi_srad'])\n",
    "my_catalog['logrho_err2'] = np.zeros_like(arc['koi_srad'])\n",
    "\n",
    "my_catalog['Teff'] = arc['koi_steff']\n",
    "my_catalog['Teff_err1'] = arc['koi_steff_err1']\n",
    "my_catalog['Teff_err2'] = arc['koi_steff_err2']\n",
    "\n",
    "my_catalog['FeH'] = arc['koi_smet']\n",
    "my_catalog['FeH_err1'] = arc['koi_smet_err1']\n",
    "my_catalog['FeH_err2'] = arc['koi_smet_err2']\n",
    "\n",
    "my_catalog['logg'] = arc['koi_slogg']\n",
    "my_catalog['logg_err1'] = arc['koi_slogg_err1']\n",
    "my_catalog['logg_err2'] = arc['koi_slogg_err2']\n",
    "\n",
    "my_catalog['limbdark_1'] = arc['koi_ldm_coeff1']\n",
    "my_catalog['limbdark_2'] = arc['koi_ldm_coeff2']\n",
    "\n",
    "my_catalog['period'] = arc['koi_period']\n",
    "my_catalog['period_err1'] = arc['koi_period_err1']\n",
    "my_catalog['period_err2'] = arc['koi_period_err2']\n",
    "\n",
    "my_catalog['epoch'] = arc['koi_time0bk']\n",
    "my_catalog['epoch_err1'] = arc['koi_time0bk_err1']\n",
    "my_catalog['epoch_err2'] = arc['koi_time0bk_err2']\n",
    "\n",
    "my_catalog['prad'] = arc['koi_prad']\n",
    "my_catalog['prad_err1'] = arc['koi_prad_err1']\n",
    "my_catalog['prad_err2'] = arc['koi_prad_err2']\n",
    "\n",
    "my_catalog['impact'] = arc['koi_impact']\n",
    "my_catalog['impact_err1'] = arc['koi_impact_err1']\n",
    "my_catalog['impact_err2'] = arc['koi_impact_err2']\n",
    "\n",
    "my_catalog['depth'] = arc['koi_depth']\n",
    "my_catalog['depth_err1'] = arc['koi_depth_err1']\n",
    "my_catalog['depth_err2'] = arc['koi_depth_err2']\n",
    "\n",
    "my_catalog['duration'] = arc['koi_duration']\n",
    "my_catalog['duration_err1'] = arc['koi_duration_err1']\n",
    "my_catalog['duration_err2'] = arc['koi_duration_err2']\n",
    "\n",
    "my_catalog['ror'] = arc['koi_ror']\n",
    "my_catalog['ror_err1'] = arc['koi_ror_err1']\n",
    "my_catalog['ror_err2'] = arc['koi_ror_err2']\n",
    "\n",
    "my_catalog['dor'] = arc['koi_dor']\n",
    "my_catalog['dor_err1'] = arc['koi_dor_err1']\n",
    "my_catalog['dor_err2'] = arc['koi_dor_err2']\n",
    "\n",
    "my_catalog['snr'] = arc['koi_model_snr']\n",
    "my_catalog['num_transits'] = arc['koi_num_transits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make KOI name for star\n",
    "for i, pname in enumerate(my_catalog['planet_name']):\n",
    "    my_catalog['koi_id'][i] = pname[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty values with NaN\n",
    "for i, k in enumerate(my_catalog.keys()):\n",
    "    bad = np.zeros(len(my_catalog[k]), dtype=\"bool\")\n",
    "    \n",
    "    for j, mck in enumerate(my_catalog[k]):\n",
    "        bad[j] = mck == ''\n",
    "    \n",
    "    my_catalog[k][bad] = \"nan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute stellar densities\n",
    "M = np.asarray(my_catalog[\"mstar\"], dtype=\"float\")\n",
    "R = np.asarray(my_catalog[\"rstar\"], dtype=\"float\")\n",
    "D = M/R**3*RHOSUN_GCM3\n",
    "\n",
    "M_err1 = np.asarray(my_catalog[\"mstar_err1\"], dtype=\"float\")\n",
    "R_err1 = np.asarray(my_catalog[\"rstar_err1\"], dtype=\"float\")\n",
    "D_err1 = np.sqrt(((R**-3)*(M_err1))**2 + ((-3*M*R**-4)*(R_err1))**2)\n",
    "\n",
    "M_err2 = np.asarray(my_catalog[\"mstar_err2\"], dtype=\"float\")\n",
    "R_err2 = np.asarray(my_catalog[\"rstar_err2\"], dtype=\"float\")\n",
    "D_err2 = -np.sqrt(((R**-3)*(M_err2))**2 + ((-3*M*R**-4)*(R_err2))**2)\n",
    "\n",
    "my_catalog[\"logrho\"] = np.log10(D)\n",
    "my_catalog[\"logrho_err1\"] = np.log10(D+D_err1) - my_catalog[\"logrho\"]\n",
    "my_catalog[\"logrho_err2\"] = np.log10(D+D_err2) - my_catalog[\"logrho\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-match Kepler vs. Gaia and combine\n",
    "\n",
    "#### This section uses Berger+ 2018 which only includes stellar radii; the catalog from Berger+ 2020 will soon be available and that will also include stellar masses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4273, 186301)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_kic = np.array(arc['kepid'], dtype='int')\n",
    "gaia_kic = np.array(gaia['kic'], dtype='int')\n",
    "\n",
    "len(arc_kic), len(gaia_kic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update Kepler stellar properties to Gaia values where available\n",
    "use = np.isin(arc_kic, gaia_kic)\n",
    "\n",
    "for i, kic in enumerate(arc_kic[:10]):\n",
    "    if use[i]:\n",
    "        my_catalog['mstar'][i] = np.squeeze(gaia['Mstar'][gaia_kic == kic])\n",
    "        my_catalog['mstar_err1'][i] = np.squeeze(gaia['Mstar_err1'][gaia_kic == kic])\n",
    "        my_catalog['mstar_err2'][i] = np.squeeze(gaia['Mstar_err2'][gaia_kic == kic])\n",
    "\n",
    "        my_catalog['rstar'][i] = np.squeeze(gaia['Rstar'][gaia_kic == kic])\n",
    "        my_catalog['rstar_err1'][i] = np.squeeze(gaia['Rstar_err1'][gaia_kic == kic])\n",
    "        my_catalog['rstar_err2'][i] = np.squeeze(gaia['Rstar_err2'][gaia_kic == kic])\n",
    "                \n",
    "        my_catalog['logg'][i] = np.squeeze(gaia['logg'][gaia_kic == kic])\n",
    "        my_catalog['logg_err1'][i] = np.squeeze(gaia['logg_err1'][gaia_kic == kic])\n",
    "        my_catalog['logg_err2'][i] = np.squeeze(gaia['logg_err2'][gaia_kic == kic])\n",
    "\n",
    "        my_catalog['FeH'][i] = np.squeeze(gaia['FeH'][gaia_kic == kic])\n",
    "        my_catalog['FeH_err1'][i] = np.squeeze(gaia['FeH_err1'][gaia_kic == kic])\n",
    "        my_catalog['FeH_err2'][i] = np.squeeze(gaia['FeH_err2'][gaia_kic == kic])\n",
    "        \n",
    "        my_catalog['Teff'][i] = np.squeeze(gaia['Teff'][gaia_kic == kic])\n",
    "        my_catalog['Teff_err1'][i] = np.squeeze(gaia['Teff_err1'][gaia_kic == kic])\n",
    "        my_catalog['Teff_err2'][i] = np.squeeze(gaia['Teff_err2'][gaia_kic == kic])\n",
    "        \n",
    "        \n",
    "        # density is a bit more complicated - Berger uses different notation convention than I do\n",
    "        D = 10**float(np.squeeze(gaia['logrho'][gaia_kic == kic]))\n",
    "        D_err1 = 10**float(np.squeeze(gaia['logrho_err1'][gaia_kic == kic]))\n",
    "        D_err2 = -10**float(np.squeeze(gaia['logrho_err2'][gaia_kic == kic]))\n",
    "        \n",
    "        my_catalog[\"logrho\"][i] = np.log10(D)\n",
    "        my_catalog[\"logrho_err1\"][i] = np.log10(D+D_err1) - my_catalog[\"logrho\"][i]\n",
    "        my_catalog[\"logrho_err2\"][i] = np.log10(D+D_err2) - my_catalog[\"logrho\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enforce limb darkening consistency via averaging (some come from different places)\n",
    "my_catalog[\"limbdark_1\"] = np.array(my_catalog[\"limbdark_1\"], dtype=\"float\")\n",
    "my_catalog[\"limbdark_2\"] = np.array(my_catalog[\"limbdark_2\"], dtype=\"float\")\n",
    "\n",
    "\n",
    "for i, koi in enumerate(my_catalog[\"koi_id\"]):\n",
    "    use = my_catalog[\"koi_id\"] == koi\n",
    "    \n",
    "    my_catalog[\"limbdark_1\"][use] = np.mean(my_catalog[\"limbdark_1\"][use])\n",
    "    my_catalog[\"limbdark_2\"][use] = np.mean(my_catalog[\"limbdark_2\"][use])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust number of planets in each system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust number of planets in each system to reflect removals \n",
    "unique_systems = np.unique(my_catalog['koi_id'])\n",
    "\n",
    "my_catalog['npl'] = np.zeros(len(my_catalog['koi_id']), dtype='int')\n",
    "\n",
    "for us in unique_systems:\n",
    "    new_npl = np.sum(my_catalog['koi_id'] == us)\n",
    "    my_catalog['npl'][my_catalog['koi_id'] == us] = new_npl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2418.,  978.,  498.,  244.,  110.,   18.,    7.,    0.]),\n",
       " array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " <a list of 8 Patch objects>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.array(my_catalog['npl'], dtype='float'), bins=np.arange(1,10), color='cornflowerblue', edgecolor='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read out catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITENEW = True\n",
    "if WRITENEW:\n",
    "    filepath = MAINPATH + 'Catalogs/cumulative_koi_catalog.csv'\n",
    "\n",
    "    with open(filepath, \"w\") as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(my_catalog.keys())\n",
    "        writer.writerows(zip(*my_catalog.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make condensed stellar parameter catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = {}\n",
    "\n",
    "stars[\"koi_id\"] = []\n",
    "stars[\"Teff\"] = []\n",
    "stars[\"Teff_err1\"] = []\n",
    "stars[\"Teff_err2\"] = []\n",
    "stars[\"logg\"] = []\n",
    "stars[\"logg_err1\"] = []\n",
    "stars[\"logg_err2\"] = []\n",
    "stars[\"FeH\"] = []\n",
    "stars[\"FeH_err1\"] = []\n",
    "stars[\"FeH_err2\"] = []\n",
    "\n",
    "for i, koi in enumerate(np.unique(my_catalog[\"koi_id\"])):\n",
    "    use = my_catalog[\"koi_id\"] == koi\n",
    "    \n",
    "    stars[\"koi_id\"].append(koi)\n",
    "    \n",
    "    for k in stars.keys():\n",
    "        if k != \"koi_id\":\n",
    "            stars[k].append(my_catalog[k][use][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITENEW = True\n",
    "if WRITENEW:\n",
    "    filepath = MAINPATH + 'Catalogs/cumulative_koi_stellar.csv'\n",
    "\n",
    "    with open(filepath, \"w\") as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(stars.keys())\n",
    "        writer.writerows(zip(*stars.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
