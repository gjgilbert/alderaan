{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy.polynomial.polynomial as poly\n",
    "import astropy\n",
    "from   astropy.io import fits as pyfits\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "from   timeit import default_timer as timer\n",
    "import warnings\n",
    "import corner\n",
    "\n",
    "from alderaan.constants import *\n",
    "import alderaan.io as io\n",
    "\n",
    "\n",
    "# flush buffer to avoid mixed outputs from progressbar\n",
    "sys.stdout.flush()\n",
    "\n",
    "# turn off FutureWarnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# start program timer\n",
    "global_start_time = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select mission, target, and paths\n",
    "MISSION = \"Simulated\"\n",
    "TARGET  = \"S00270\"\n",
    "PRIMARY_DIR = '/Users/research/projects/alderaan/'\n",
    "TRACE_FILE  = '/Users/research/projects/alderaan/Traces/' + TARGET + '/' + TARGET + '_transit_shape.fits'\n",
    "\n",
    "if MISSION == \"Simulated\":\n",
    "    CSV_FILE = PRIMARY_DIR + \"Catalogs/simulated_catalog.csv\"\n",
    "    TRUE_TTV_DIR = PRIMARY_DIR + \"Simulations/TTVs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure the necessary paths exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory in which to find lightcurve data\n",
    "if MISSION == 'Kepler': DOWNLOAD_DIR = PRIMARY_DIR + 'MAST_downloads/'\n",
    "if MISSION == 'Simulated': DOWNLOAD_DIR = PRIMARY_DIR + 'Simulations/'\n",
    "\n",
    "# directories in which to place pipeline outputs    \n",
    "FIGURE_DIR    = PRIMARY_DIR + 'Figures/' + TARGET + '/'\n",
    "TRACE_DIR     = PRIMARY_DIR + 'Traces/' + TARGET + '/'\n",
    "QUICK_TTV_DIR = PRIMARY_DIR + 'QuickTTVs/' + TARGET + '/'\n",
    "DLC_DIR       = PRIMARY_DIR + 'Detrended_lightcurves/' + TARGET + '/'\n",
    "NOISE_DIR     = PRIMARY_DIR + 'Noise_models/' + TARGET + '/'\n",
    "\n",
    "# check if all the paths exist and create them if not\n",
    "if os.path.exists(FIGURE_DIR) == False:\n",
    "    os.mkdir(FIGURE_DIR)\n",
    "    \n",
    "if os.path.exists(TRACE_DIR) == False:\n",
    "    os.mkdir(TRACE_DIR)\n",
    "    \n",
    "if os.path.exists(QUICK_TTV_DIR) == False:\n",
    "    os.mkdir(QUICK_TTV_DIR)\n",
    "    \n",
    "if os.path.exists(DLC_DIR) == False:\n",
    "    os.mkdir(DLC_DIR)\n",
    "    \n",
    "if os.path.exists(NOISE_DIR) == False:\n",
    "    os.mkdir(NOISE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get shape model posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in the fits file with saved traces\n",
    "\n",
    "with pyfits.open(TRACE_FILE) as trace:\n",
    "    header  = trace[0].header\n",
    "    hdulist = pyfits.HDUList(trace)\n",
    "    \n",
    "    NDRAWS, NPL = trace['RP'].shape\n",
    "    \n",
    "    # stellar parameters\n",
    "    RSTAR  = trace['RSTAR'].data\n",
    "    MSTAR  = trace['MSTAR'].data\n",
    "    U      = trace['U'].data\n",
    "    U1, U2 = U[:,0], U[:,1]\n",
    "    \n",
    "    # planetary parameters\n",
    "    T0   = trace['T0'].data\n",
    "    P    = trace['P'].data\n",
    "    LOGR = trace['LOGR'].data         # [log(R_sun)]\n",
    "    RP   = trace['RP'].data * RSRE    # [R_earth]\n",
    "    B    = trace['B'].data\n",
    "    \n",
    "    # TTV parameters\n",
    "    TTS = [None]*NPL\n",
    "\n",
    "    for npl in range(NPL):    \n",
    "        TTS[npl] = trace['TTS_{0}'.format(npl)].data\n",
    "            \n",
    "\n",
    "    C0 = trace['C0'].data\n",
    "    C1 = trace['C1'].data\n",
    "    \n",
    "    try: C2 = trace['C2'].data\n",
    "    except: pass\n",
    "    \n",
    "    try: C3 = trace['C3'].data\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyfits.open(TRACE_FILE) as trace:\n",
    "    header  = trace[0].header\n",
    "    hdulist = pyfits.HDUList(trace)\n",
    "    \n",
    "    NDRAWS, NPL = trace['RP'].shape\n",
    "    \n",
    "    \n",
    "    # GP parameters\n",
    "    LOGSW4 = np.zeros((NDRAWS,4))\n",
    "    LOGW0  = np.zeros((NDRAWS,4))\n",
    "    LOGQ   = np.zeros((NDRAWS,4))\n",
    "    \n",
    "    for z in range(4):\n",
    "        try: LOGSW4[:,z] = trace['LOGSW4_{0}'.format(z)].data\n",
    "        except: pass\n",
    "        \n",
    "        try: LOGW0[:,z] = trace['LOGW0_{0}'.format(z)].data\n",
    "        except: pass\n",
    "        \n",
    "        try: LOGQ[:,z] = trace['LOGQ_{0}'.format(z)].data\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npl in range(NPL):\n",
    "    per = (np.median(P[:,npl]), np.std(P[:,npl]))\n",
    "    rad = (np.median(RP[:,npl]), astropy.stats.mad_std(RP[:,npl]))\n",
    "        \n",
    "    print(\"\\nPLANET {0}\".format(npl))\n",
    "    print(\"  period = {:.3f} +/- {:.3f}\\t[days]\".format(per[0],per[1]))\n",
    "    print(\"  radius = {:.3f} +/- {:.3f}\\t[R_earth]\".format(rad[0],rad[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For simulated data, read in ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MISSION == \"Simulated\":\n",
    "    # Read in the data from csv file\n",
    "    print('Reading in simulated \"ground truth\" data from csv file')\n",
    "\n",
    "    # read in a csv file containing info on targets\n",
    "    csv_keys, csv_values = io.read_csv_file(CSV_FILE)\n",
    "\n",
    "    # put these csv data into a dictionary\n",
    "    target_dict = {}\n",
    "    for k in csv_keys: \n",
    "        target_dict[k] = io.get_csv_data(k, csv_keys, csv_values)\n",
    "\n",
    "\n",
    "    # pull relevant quantities and establish GLOBAL variables\n",
    "    KOI_ID = \"K\" + TARGET[1:]\n",
    "\n",
    "    use = np.array(target_dict['koi_id']) == KOI_ID\n",
    "    KIC = np.array(target_dict['kic_id'], dtype='int')[use]\n",
    "\n",
    "    Rs_true = np.array(target_dict['rstar'], dtype='float')[use]\n",
    "    Ms_true = np.array(target_dict['mstar'], dtype='float')[use]\n",
    "    u1_true = np.array(target_dict['limbdark_1'], dtype='float')[use]\n",
    "    u2_true = np.array(target_dict['limbdark_2'], dtype='float')[use]\n",
    "\n",
    "    T0_true = np.array(target_dict['epoch'],  dtype='float')[use]\n",
    "    P_true  = np.array(target_dict['period'], dtype='float')[use]\n",
    "    rp_true = np.array(target_dict['rp_true_e'], dtype='float')[use]\n",
    "    b_true  = np.array(target_dict['b_true'], dtype='float')[use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some consistency checks\n",
    "if all(k == KIC[0] for k in KIC): KIC = KIC[0]\n",
    "else: raise ValueError('There are inconsistencies with KIC in the csv input file')\n",
    "\n",
    "if all(r == Rs_true[0] for r in Rs_true): Rs_true = Rs_true[0]\n",
    "else: raise ValueError('There are inconsistencies with RSTAR in the csv input file')\n",
    "\n",
    "if all(m == Ms_true[0] for m in Ms_true): Ms_true = Ms_true[0]\n",
    "else: raise ValueError('There are inconsistencies with MSTAR in the csv input file')\n",
    "\n",
    "if all(u == u1_true[0] for u in u1_true): u1_true = u1_true[0]\n",
    "else: raise ValueError('There are inconsistencies with U1 in the csv input file')\n",
    "\n",
    "if all(u == u2_true[0] for u in u2_true): u2_true = u2_true[0]\n",
    "else: raise ValueError('There are inconsistencies with U2 in the csv input file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort planet truths by period\n",
    "order = np.argsort(P_true)\n",
    "\n",
    "T0_true = T0_true[order]\n",
    "P_true  = P_true[order]\n",
    "rp_true = rp_true[order]\n",
    "b_true  = b_true[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"true radii:\", rp_true)\n",
    "print(\"true impact:\", b_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make corner plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [MSTAR, RSTAR, U1, U2]\n",
    "labels = [\"MSTAR\", \"RSTAR\", \"U1\", \"U2\"]\n",
    "\n",
    "for npl in range(NPL):\n",
    "    data.append(B[:,npl])\n",
    "    labels.append(\"B_{0}\".format(npl))\n",
    "\n",
    "data = np.stack(data).swapaxes(0,1)\n",
    "fig = corner.corner(data, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.stack([RSTAR, MSTAR, U1, U2]).swapaxes(0,1)\n",
    "labels = ['Rstar', 'Mstar', 'U1', 'U2']\n",
    "\n",
    "if MISSION == \"Simulated\":\n",
    "    truths = [Rs_true, Ms_true, u1_true, u2_true]\n",
    "else:\n",
    "    truths = None\n",
    "\n",
    "fig = corner.corner(data, labels=labels, truths=truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for npl in range(NPL):\n",
    "    data = np.stack([T0[:,npl], P[:,npl], RP[:,npl], B[:,npl]]).swapaxes(0,1)\n",
    "    labels = ['$T_0$', 'P', '$r_p$', 'b']\n",
    "    \n",
    "    \n",
    "    if MISSION == \"Simulated\":\n",
    "        truths = [None, None, rp_true[npl], b_true[npl]]\n",
    "    else:\n",
    "        truths = None\n",
    "\n",
    "\n",
    "    fig = corner.corner(data, labels=labels, truths=truths, color='C{0}'.format(npl), truth_color=\"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for npl in range(NPL):\n",
    "    try:\n",
    "        data = np.stack([C0[:,npl], C1[:,npl], C2[:,npl], C3[:,npl]]).swapaxes(0,1)\n",
    "        labels = ['C0', 'C1', 'C2', 'C3']\n",
    "\n",
    "        fig = corner.corner(data, labels=labels, color='C{0}'.format(npl))\n",
    "        \n",
    "    except:\n",
    "        try:\n",
    "            data = np.stack([C0[:,npl], C1[:,npl], C2[:,npl]]).swapaxes(0,1)\n",
    "            labels = ['C0', 'C1', 'C2']\n",
    "\n",
    "            fig = corner.corner(data, labels=labels, color='C{0}'.format(npl))\n",
    "        \n",
    "        except:\n",
    "            try:\n",
    "                data = np.stack([C0[:,npl], C1[:,npl]]).swapaxes(0,1)\n",
    "                labels = ['C0', 'C1']\n",
    "\n",
    "                fig = corner.corner(data, labels=labels, color='C{0}'.format(npl))\n",
    "\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for z in range(4):\n",
    "    data  = []\n",
    "    labels = []\n",
    "\n",
    "    if np.sum(LOGSW4[:,z] != 0):\n",
    "        data.append(LOGSW4[:,z])\n",
    "        labels.append('LogSw4')\n",
    "        \n",
    "    if np.sum(LOGW0[:,z] != 0):\n",
    "        data.append(LOGW0[:,z])\n",
    "        labels.append('Logw0')    \n",
    "    \n",
    "    if np.sum(LOGQ[:,z] != 0):\n",
    "        data.append(LOGQ[:,z])\n",
    "        labels.append('LogQ')\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        data = np.stack(data).swapaxes(0,1)\n",
    "        fig = corner.corner(data, labels=labels)\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get transit times, linear ephemeris and O-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MISSION == \"Simulated\":\n",
    "    true_inds = []\n",
    "    true_tts  = []\n",
    "    true_omc  = []\n",
    "    \n",
    "    for npl in range(NPL):\n",
    "        data_in = np.loadtxt(TRUE_TTV_DIR + TARGET + '_{:02d}'.format(npl) + '_sim_ttvs.txt')\n",
    "        \n",
    "        inds, tts = np.atleast_2d(data_in).swapaxes(0,1)\n",
    "        \n",
    "        ephem = poly.polyval(inds, poly.polyfit(inds, tts, 1))\n",
    "        \n",
    "        true_inds.append(inds)\n",
    "        true_tts.append(tts)\n",
    "        true_omc.append((tts-ephem)*24*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.zeros(NPL)\n",
    "periods = np.zeros(NPL)\n",
    "\n",
    "transit_times = []\n",
    "ephemeris = []\n",
    "transit_inds = []\n",
    "\n",
    "for npl in range(NPL):   \n",
    "    transit_times.append(np.median(TTS[npl], axis=0))\n",
    "    \n",
    "    t0  = np.median(T0[:,npl])\n",
    "    per = np.median(P[:,npl])\n",
    "    tts = transit_times[npl]\n",
    "    \n",
    "    tinds = np.array(np.floor((tts - t0 + per/2) / per), dtype='int')\n",
    "    \n",
    "    epochs[npl] = t0\n",
    "    periods[npl] = per\n",
    "    ephemeris.append(t0 + per*tinds)\n",
    "    transit_inds.append(tinds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(NPL, figsize=(12,8))\n",
    "\n",
    "for npl in range(NPL):    \n",
    "    xtime = transit_times[npl]\n",
    "    yomc  = (transit_times[npl]-ephemeris[npl])*24*60\n",
    "    \n",
    "    axes[npl].plot(xtime, yomc, \"o\", color='C{0}'.format(npl))\n",
    "    axes[npl].set_ylabel('O-C [min]', fontsize=20)\n",
    "    \n",
    "    if MISSION == \"Simulated\":\n",
    "        axes[npl].plot(true_tts[npl], true_omc[npl], c=\"grey\")\n",
    "    \n",
    "axes[NPL-1].set_xlabel('Time [BJKD]', fontsize=20) \n",
    "\n",
    "plt.savefig(FIGURE_DIR + TARGET + '_ttvs_shape.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
