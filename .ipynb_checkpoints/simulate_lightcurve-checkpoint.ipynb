{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Lightcurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.optimize as op\n",
    "import scipy.signal as sig\n",
    "from   scipy import stats\n",
    "from   scipy import fftpack\n",
    "from   scipy import ndimage\n",
    "from   scipy.interpolate import UnivariateSpline\n",
    "import astropy\n",
    "from   astropy.io import fits as pyfits\n",
    "from   sklearn.cluster import KMeans\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import importlib as imp\n",
    "import glob\n",
    "from   timeit import default_timer as timer\n",
    "import warnings\n",
    "import progressbar\n",
    "import argparse\n",
    "import json\n",
    "from   copy import deepcopy\n",
    "\n",
    "import lightkurve as lk\n",
    "import exoplanet as exo\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import pymc3 as pm\n",
    "import corner\n",
    "\n",
    "from alderaan.constants import *\n",
    "from alderaan.utils import *\n",
    "from alderaan.Planet import *\n",
    "from alderaan.LiteCurve import *\n",
    "import alderaan.io as io\n",
    "import alderaan.detrend as detrend\n",
    "import alderaan.noise as noise\n",
    "\n",
    "\n",
    "# flush buffer to avoid mixed outputs from progressbar\n",
    "sys.stdout.flush()\n",
    "\n",
    "# turn off FutureWarnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# start program timer\n",
    "global_start_time = timer()\n",
    "\n",
    "# LCIT and SCIT in [days]\n",
    "lcit = LCIT/60/24\n",
    "scit = SCIT/3600/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually set I/O parameters\n",
    "#### User should manually set MISSION, TARGET, PRIMARY_DIR,  and CSV_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select mission, target, and paths\n",
    "SIM_ID = \"S02099\"\n",
    "PRIMARY_DIR  = '/Users/research/projects/alderaan/'\n",
    "\n",
    "KOI_FILE = PRIMARY_DIR + \"Catalogs/cumulative_koi_catalog.csv\"\n",
    "#SIM_FILE = PRIMARY_DIR + \"Catalogs/simulated_catalog_eccentric.csv\"\n",
    "SIM_FILE = PRIMARY_DIR + \"Catalogs/simulated_catalog_radius_valley.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's where we parse the inputs\n",
    "try:\n",
    "    parser = argparse.ArgumentParser(description=\"Inputs for ALDERAAN transit fiting pipeline\")\n",
    "    parser.add_argument(\"--sim_id\", default=None, type=str, required=True, \\\n",
    "                        help=\"Target name; see ALDERAAN documentation for acceptable formats\")\n",
    "    parser.add_argument(\"--primary_dir\", default=None, type=str, required=True, \\\n",
    "                        help=\"Primary directory path for accessing lightcurve data and saving outputs\")\n",
    "    parser.add_argument(\"--sim_file\", default=None, type=str, required=True, \\\n",
    "                        help=\"Path to .csv file containing simulated planet parameters\")\n",
    "    parser.add_argument(\"--koi_file\", default=None, type=str, required=True, \\\n",
    "                        help=\"Path to .csv file containing real (measured) planet parameters\")\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    SIM_ID       = args.sim_id\n",
    "    PRIMARY_DIR  = args.primary_dir\n",
    "    SIM_FILE     = args.sim_file    \n",
    "    KOI_FILE     = args.koi_file    \n",
    "    \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure the necessary paths exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory in which to find/store inputs/outputs\n",
    "DOWNLOAD_DIR = PRIMARY_DIR + 'MAST_downloads/'\n",
    "SIM_DIR  = PRIMARY_DIR + 'Simulations/' \n",
    "\n",
    "# check if all the paths exist and create them if not\n",
    "if os.path.exists(SIM_DIR + 'Lightcurves/') == False:\n",
    "    os.mkdir(SIM_DIR + 'Lightcurves/')\n",
    "    \n",
    "if os.path.exists(SIM_DIR + \"Lightcurves/Kepler/\") == False:\n",
    "    os.mkdir(SIM_DIR + \"Lightcurves/Kepler/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in star and planet parameters for REAL KOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data from csv file\n",
    "print('Reading in data from csv file')\n",
    "\n",
    "# read in a csv file containing info on targets\n",
    "KOI_ID = \"K\" + SIM_ID[1:]\n",
    "csv_keys, csv_values = io.read_csv_file(KOI_FILE)\n",
    "\n",
    "# put these csv data into a dictionary\n",
    "target_dict = {}\n",
    "for k in csv_keys: \n",
    "    target_dict[k] = io.get_csv_data(k, csv_keys, csv_values)\n",
    "\n",
    "    \n",
    "# pull relevant quantities and establish GLOBAL variables\n",
    "use = np.array(target_dict['koi_id']) == KOI_ID\n",
    "\n",
    "KIC = np.array(target_dict['kic_id'], dtype='int')[use]\n",
    "NPL = np.array(target_dict['npl'], dtype='int')[use]\n",
    "\n",
    "RSTAR = np.array(target_dict['rstar'], dtype='float')[use]\n",
    "MSTAR = np.array(target_dict['mstar'], dtype='float')[use]\n",
    "\n",
    "U1 = np.array(target_dict['limbdark_1'], dtype='float')[use]\n",
    "U2 = np.array(target_dict['limbdark_2'], dtype='float')[use]\n",
    "\n",
    "PERIODS = np.array(target_dict['period'], dtype='float')[use]\n",
    "EPOCHS  = np.array(target_dict['epoch'],  dtype='float')[use]\n",
    "DEPTHS  = np.array(target_dict['depth'], dtype='float')[use]*1e-6          # [ppm] --> [unitless]\n",
    "DURS    = np.array(target_dict['duration'], dtype='float')[use]/24         # [hrs] --> [days]\n",
    "IMPACTS = np.array(target_dict['impact'], dtype='float')[use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some consistency checks\n",
    "if all(k == KIC[0] for k in KIC): KIC = KIC[0]\n",
    "else: raise ValueError('There are inconsistencies with KIC in the csv input file')\n",
    "\n",
    "if all(n == NPL[0] for n in NPL): NPL = NPL[0]\n",
    "else: raise ValueError('There are inconsistencies with NPL in the csv input file')\n",
    "\n",
    "if all(r == RSTAR[0] for r in RSTAR): RSTAR = RSTAR[0]\n",
    "else: raise ValueError('There are inconsistencies with RSTAR in the csv input file') \n",
    "    \n",
    "if all(m == MSTAR[0] for m in MSTAR): MSTAR = MSTAR[0]\n",
    "else: raise ValueError('There are inconsistencies with MSTAR in the csv input file')\n",
    "    \n",
    "if all(u == U1[0] for u in U1): U1 = U1[0]\n",
    "else: raise ValueError('There are inconsistencies with U1 in the csv input file')\n",
    "\n",
    "if all(u == U2[0] for u in U2): U2 = U2[0]\n",
    "else: raise ValueError('There are inconsistencies with U2 in the csv input file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Holczer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOLCZER_FILE = PRIMARY_DIR + \"Catalogs/holczer_2016_kepler_ttvs.txt\"\n",
    "\n",
    "holczer_data = np.loadtxt(HOLCZER_FILE, usecols=[0,1,2,3])\n",
    "\n",
    "holczer_inds = []\n",
    "holczer_tts  = []\n",
    "holczer_pers = []\n",
    "\n",
    "for npl in range(NPL):\n",
    "    koi = int(KOI_ID[1:]) + 0.01*(1+npl)\n",
    "    use = np.isclose(holczer_data[:,0], koi, rtol=1e-10, atol=1e-10)\n",
    "\n",
    "    # Holczer uses BJD -24548900; BJKD = BJD - 2454833\n",
    "    if np.sum(use) > 0:\n",
    "        holczer_inds.append(np.array(holczer_data[use,1], dtype=\"int\"))\n",
    "        holczer_tts.append(holczer_data[use,2] + holczer_data[use,3]/24/60 + 67)\n",
    "        holczer_pers.append(np.median(holczer_tts[npl][1:] - holczer_tts[npl][:-1]))\n",
    "\n",
    "    else:\n",
    "        holczer_inds.append(None)\n",
    "        holczer_tts.append(None)\n",
    "        holczer_pers.append(np.nan)\n",
    "\n",
    "holczer_pers = np.asarray(holczer_pers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in pre-downloaded lightcurve data\n",
    "#### Kepler data can be retrieved by running the script \"download_from_MAST.py\"\n",
    "#### Simulated data can be produced by running the script \"simulate_lightcurve.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short cadence\n",
    "try:\n",
    "    sc_path  = glob.glob(DOWNLOAD_DIR + 'mastDownload/Kepler/kplr' + '{0:09d}'.format(KIC) + '*_sc*/')[0]\n",
    "    sc_files = glob.glob(sc_path + '*')\n",
    "\n",
    "    sc_rawdata_list = []\n",
    "    for i, scf in enumerate(sc_files):\n",
    "        sc_rawdata_list.append(lk.read(sc_files[i]))\n",
    "\n",
    "    sc_raw_collection = lk.LightCurveCollection(sc_rawdata_list)\n",
    "    sc_data = detrend.cleanup_lkfc(sc_raw_collection, KIC)\n",
    "\n",
    "\n",
    "except:\n",
    "    sc_data = lk.LightCurveCollection([])\n",
    "\n",
    "    \n",
    "sc_quarters = []\n",
    "for i, scd in enumerate(sc_data):\n",
    "    sc_quarters.append(scd.quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long cadence\n",
    "try:\n",
    "    lc_path  = glob.glob(DOWNLOAD_DIR + 'mastDownload/Kepler/kplr' + '{0:09d}'.format(KIC) + '*_lc*/')[0]\n",
    "    lc_files = glob.glob(lc_path + '*')\n",
    "\n",
    "    lc_rawdata_list = []\n",
    "    for i, lcf in enumerate(lc_files):\n",
    "        lkread = lk.read(lc_files[i])\n",
    "\n",
    "        if ~np.isin(lkread.quarter, sc_quarters):\n",
    "            lc_rawdata_list.append(lkread)\n",
    "\n",
    "    lc_raw_collection = lk.LightCurveCollection(lc_rawdata_list)\n",
    "    lc_data = detrend.cleanup_lkfc(lc_raw_collection, KIC)\n",
    "\n",
    "\n",
    "except:\n",
    "    lc_data = lk.LightCurveCollection([])\n",
    "\n",
    "    \n",
    "lc_quarters = []\n",
    "for i, lcd in enumerate(lc_data):\n",
    "    lc_quarters.append(lcd.quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the time baseline\n",
    "time_min = []\n",
    "time_max = []\n",
    "\n",
    "try:\n",
    "    for i, scd in enumerate(sc_data):\n",
    "        time_min.append(scd.time.value.min())\n",
    "        time_max.append(scd.time.value.max())\n",
    "        \n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "try:\n",
    "    for i, lcd in enumerate(lc_data):\n",
    "        time_min.append(lcd.time.value.min())\n",
    "        time_max.append(lcd.time.value.max())\n",
    "        \n",
    "except:\n",
    "    pass\n",
    "    \n",
    "    \n",
    "TIME_START = np.min(time_min)\n",
    "TIME_END   = np.max(time_max)\n",
    "\n",
    "if TIME_START < 0:\n",
    "    raise ValueError(\"START TIME [BKJD] is negative...this will cause problems\")\n",
    "\n",
    "\n",
    "# put epochs in range (TIME_START, TIME_START + PERIOD)\n",
    "for npl in range(NPL):\n",
    "    if EPOCHS[npl] < TIME_START:\n",
    "        adj = 1 + (TIME_START - EPOCHS[npl])//PERIODS[npl]\n",
    "        EPOCHS[npl] += adj*PERIODS[npl]        \n",
    "        \n",
    "    if EPOCHS[npl] > (TIME_START + PERIODS[npl]):\n",
    "        adj = (EPOCHS[npl] - TIME_START)//PERIODS[npl]\n",
    "        EPOCHS[npl] -= adj*PERIODS[npl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Initialize Planet objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Planet objects\n",
    "print('Initializing %d Planet objects' %NPL)\n",
    "\n",
    "planets = []\n",
    "for npl in range(NPL):\n",
    "    p = Planet()\n",
    "    \n",
    "    # put in some basic transit parameters\n",
    "    p.epoch    = EPOCHS[npl]\n",
    "    p.period   = PERIODS[npl]\n",
    "    p.depth    = DEPTHS[npl]\n",
    "    p.duration = DURS[npl]\n",
    "    p.impact   = IMPACTS[npl]           \n",
    "    p.radius   = np.sqrt(p.depth*RSTAR)*RSRE\n",
    "        \n",
    "    # estimate transit times from linear ephemeris\n",
    "    p.tts = np.arange(p.epoch, TIME_END, p.period)\n",
    "\n",
    "    # make transit indexes\n",
    "    p.index = np.array(np.round((p.tts-p.epoch)/p.period),dtype='int')\n",
    "    \n",
    "    # add to list\n",
    "    planets.append(p)\n",
    "\n",
    "\n",
    "# put planets in order by period\n",
    "order = np.argsort(PERIODS)\n",
    "\n",
    "sorted_planets = []\n",
    "for npl in range(NPL):\n",
    "    sorted_planets.append(planets[order[npl]])\n",
    "\n",
    "planets = np.copy(sorted_planets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if Holczer TTVs exist, and if so, replace the linear ephemeris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npl in range(NPL):\n",
    "    match = np.isclose(holczer_pers, p.period, rtol=0.1, atol=DURS.max())\n",
    "    \n",
    "    if np.sum(match) > 1:\n",
    "        raise ValueError(\"Something has gone wrong matching periods between DR25 and Holczer+ 2016\")\n",
    "        \n",
    "    if np.sum(match) == 1:\n",
    "        loc = np.squeeze(np.where(match))\n",
    "    \n",
    "        hinds = holczer_inds[loc]\n",
    "        htts  = holczer_tts[loc]\n",
    "        \n",
    "        for i, t0 in enumerate(p.tts):\n",
    "            for j, tH in enumerate(htts):\n",
    "                if np.abs(t0-tH)/p.period < 0.25:\n",
    "                    p.tts[i] = tH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and remove known transits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, scd in enumerate(sc_data):\n",
    "    tmin = scd.time.value.min()\n",
    "    tmax = scd.time.value.max()\n",
    "    \n",
    "    xtime = np.array(scd.time.value, dtype=\"float64\")\n",
    "    yflux = np.array(scd.flux.value, dtype=\"float64\")\n",
    "    \n",
    "    \n",
    "    # grab the transit times that are found in this quarter\n",
    "    transit_times = []\n",
    "    transit_inds  = []\n",
    "    \n",
    "    radii = []\n",
    "    impacts = []\n",
    "    periods = []\n",
    "    \n",
    "    for npl, p in enumerate(planets):\n",
    "        use = (p.tts > tmin)*(p.tts < tmax)\n",
    "        \n",
    "        if np.sum(use) > 0:\n",
    "            transit_times.append(p.tts[use])\n",
    "            transit_inds.append(np.arange(np.sum(use), dtype=\"int\"))\n",
    "        \n",
    "            radii.append(p.radius/RSRE)\n",
    "            impacts.append(p.impact)\n",
    "            periods.append(p.period)\n",
    "            \n",
    "    \n",
    "    # model the transits\n",
    "    if len(transit_times) > 0:\n",
    "        starrystar = exo.LimbDarkLightCurve([U1,U2])\n",
    "        orbit  = exo.orbits.TTVOrbit(transit_times=transit_times, transit_inds=transit_inds, period=periods,\n",
    "                                     b=impacts, r_star=RSTAR, m_star=MSTAR)\n",
    "\n",
    "\n",
    "        light_curves = starrystar.get_light_curve(orbit=orbit, r=radii, t=xtime, oversample=1)\n",
    "        model_flux = 1.0 + pm.math.sum(light_curves, axis=-1).eval()\n",
    "    \n",
    "    else:\n",
    "        model_flux = np.ones_like(yflux)\n",
    "    \n",
    "\n",
    "    # check that transits were properly removed\n",
    "    mask = np.zeros_like(sc_data[i].time)\n",
    "\n",
    "    for npl, p in enumerate(planets):\n",
    "        for t0 in p.tts:\n",
    "            mask += np.abs(xtime - t0)/p.duration < 1.5\n",
    "\n",
    "    mask = mask > 0\n",
    "    \n",
    "    yclean = yflux/model_flux\n",
    "    \n",
    "    npts = 1+60*int(3*DURS.max()*24)\n",
    "    ytrend = boxcar_smooth(ndimage.median_filter(yclean, size=npts), winsize=npts)\n",
    "        \n",
    "    out = np.abs(yclean-ytrend)/astropy.stats.mad_std(yclean-ytrend) > 3.0\n",
    "    out[~mask] = False\n",
    "    \n",
    "    yclean[out] = ytrend[out] + np.random.normal(size=np.sum(out))*astropy.stats.mad_std(yclean-ytrend)\n",
    "    \n",
    "    \n",
    "    # save the cleaned lightcurve\n",
    "    sc_data[i].flux = np.copy(yclean)\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.plot(xtime, yflux, \"k.\")\n",
    "    plt.plot(xtime, model_flux, c=\"red\", lw=2)\n",
    "    plt.xlim(xtime.min(), xtime.max())\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(20,2))\n",
    "    plt.plot(xtime, yclean, \".\", c=\"lightgrey\")\n",
    "    plt.plot(xtime, ytrend, \"orange\")\n",
    "    plt.plot(xtime[out], yclean[out], \".\", c=\"mediumblue\")\n",
    "    plt.xlim(xtime.min(), xtime.max())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, lcd in enumerate(lc_data):\n",
    "    tmin = lcd.time.value.min()\n",
    "    tmax = lcd.time.value.max()\n",
    "    \n",
    "    xtime = np.array(lcd.time.value, dtype=\"float64\")\n",
    "    yflux = np.array(lcd.flux.value, dtype=\"float64\")\n",
    "    \n",
    "    \n",
    "    # grab the transit times that are found in this quarter\n",
    "    transit_times = []\n",
    "    transit_inds  = []\n",
    "    \n",
    "    radii = []\n",
    "    impacts = []\n",
    "    periods = []\n",
    "    \n",
    "    for npl, p in enumerate(planets):\n",
    "        use = (p.tts > tmin)*(p.tts < tmax)\n",
    "        \n",
    "        if np.sum(use) > 0:\n",
    "            transit_times.append(p.tts[use])\n",
    "            transit_inds.append(np.arange(np.sum(use), dtype=\"int\"))\n",
    "        \n",
    "            radii.append(p.radius/RSRE)\n",
    "            impacts.append(p.impact)\n",
    "            periods.append(p.period)\n",
    "            \n",
    "            \n",
    "    # model the transits\n",
    "    if len(transit_times) > 0:\n",
    "        starrystar = exo.LimbDarkLightCurve([U1,U2])\n",
    "        orbit  = exo.orbits.TTVOrbit(transit_times=transit_times, transit_inds=transit_inds, period=periods,\n",
    "                                     b=impacts, r_star=RSTAR, m_star=MSTAR)\n",
    "\n",
    "        light_curves = starrystar.get_light_curve(orbit=orbit, r=radii, t=xtime, oversample=15)\n",
    "        model_flux = 1.0 + pm.math.sum(light_curves, axis=-1).eval()\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        model_flux = np.ones_like(yflux)\n",
    "    \n",
    "    \n",
    "    # check that transits were properly removed\n",
    "    mask = np.zeros_like(lc_data[i].time)\n",
    "\n",
    "    for npl, p in enumerate(planets):\n",
    "        for t0 in p.tts:\n",
    "            mask += np.abs(xtime - t0)/p.duration < 1.5\n",
    "\n",
    "    mask = mask > 0\n",
    "    \n",
    "    yclean = yflux/model_flux\n",
    "    \n",
    "    npts = 1+2*int(3*DURS.max()*24)\n",
    "    ytrend = boxcar_smooth(ndimage.median_filter(yclean, size=npts), winsize=npts)\n",
    "        \n",
    "    out = np.abs(yclean-ytrend)/astropy.stats.mad_std(yclean-ytrend) > 3.0\n",
    "    out[~mask] = False\n",
    "    \n",
    "    yclean[out] = ytrend[out] + np.random.normal(size=np.sum(out))*astropy.stats.mad_std(yclean-ytrend)\n",
    "    \n",
    "    \n",
    "    # save the cleaned lightcurve\n",
    "    lc_data[i].flux = np.copy(yclean)\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.plot(xtime, yflux, \"k.\")\n",
    "    plt.plot(xtime, model_flux, c=\"red\", lw=2)\n",
    "    plt.xlim(xtime.min(), xtime.max())\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(20,2))\n",
    "    plt.plot(xtime, yclean, \".\", c=\"lightgrey\")\n",
    "    plt.plot(xtime, ytrend, \"orange\")\n",
    "    plt.plot(xtime[out], yclean[out], \".\", c=\"mediumblue\")\n",
    "    plt.xlim(xtime.min(), xtime.max())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data for simulated planets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data from csv file\n",
    "print('Reading in data from csv file')\n",
    "\n",
    "# read in a csv file containing info on targets\n",
    "csv_keys, csv_values = io.read_csv_file(SIM_FILE)\n",
    "\n",
    "# put these csv data into a dictionary\n",
    "target_dict = {}\n",
    "for k in csv_keys: \n",
    "    target_dict[k] = io.get_csv_data(k, csv_keys, csv_values)\n",
    "\n",
    "    \n",
    "# pull relevant quantities and establish GLOBAL variables\n",
    "use = np.array(target_dict['koi_id']) == KOI_ID\n",
    "\n",
    "KIC = np.array(target_dict['kic_id'], dtype='int')[use]\n",
    "NPL = np.array(target_dict['npl'], dtype='int')[use]\n",
    "\n",
    "RSTAR = np.array(target_dict['rstar'], dtype='float')[use]\n",
    "MSTAR = np.array(target_dict['mstar'], dtype='float')[use]\n",
    "\n",
    "U1 = np.array(target_dict['limbdark_1'], dtype='float')[use]\n",
    "U2 = np.array(target_dict['limbdark_2'], dtype='float')[use]\n",
    "\n",
    "PERIODS = np.array(target_dict['period'], dtype='float')[use]\n",
    "EPOCHS  = np.array(target_dict['epoch'],  dtype='float')[use]\n",
    "DEPTHS  = np.array(target_dict['depth'], dtype='float')[use]*1e-6          # [ppm] --> [unitless]\n",
    "DURS    = np.array(target_dict['duration'], dtype='float')[use]/24         # [hrs] --> [days]\n",
    "IMPACTS = np.array(target_dict['impact'], dtype='float')[use]\n",
    "RADII   = np.array(target_dict['prad'], dtype='float')[use]\n",
    "ECCS    = np.array(target_dict['ecc'], dtype='float')[use]\n",
    "OMEGAS  = np.array(target_dict['omega'], dtype='float')[use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some consistency checks\n",
    "if all(k == KIC[0] for k in KIC): KIC = KIC[0]\n",
    "else: raise ValueError('There are inconsistencies with KIC in the csv input file')\n",
    "\n",
    "if all(n == NPL[0] for n in NPL): NPL = NPL[0]\n",
    "else: raise ValueError('There are inconsistencies with NPL in the csv input file')\n",
    "\n",
    "if all(r == RSTAR[0] for r in RSTAR): RSTAR = RSTAR[0]\n",
    "else: raise ValueError('There are inconsistencies with RSTAR in the csv input file') \n",
    "    \n",
    "if all(m == MSTAR[0] for m in MSTAR): MSTAR = MSTAR[0]\n",
    "else: raise ValueError('There are inconsistencies with MSTAR in the csv input file')\n",
    "    \n",
    "if all(u == U1[0] for u in U1): U1 = U1[0]\n",
    "else: raise ValueError('There are inconsistencies with U1 in the csv input file')\n",
    "\n",
    "if all(u == U2[0] for u in U2): U2 = U2[0]\n",
    "else: raise ValueError('There are inconsistencies with U2 in the csv input file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in pre-simulated transit times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_inds = []\n",
    "transit_times = []\n",
    "\n",
    "for npl in range(NPL):\n",
    "\n",
    "    fname_in = SIM_DIR + \"TTVs/\" + SIM_ID + \"_0{0}_sim_ttvs.txt\".format(npl)\n",
    "    data_in  = np.loadtxt(fname_in).swapaxes(0,1)\n",
    "    \n",
    "    transit_inds.append(np.array(data_in[0], dtype=\"int\"))\n",
    "    transit_times.append(np.array(data_in[1], dtype=\"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize new Planet objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Planet objects\n",
    "print('Initializing %d Planet objects' %NPL)\n",
    "\n",
    "planets = []\n",
    "for npl in range(NPL):\n",
    "    p = Planet()\n",
    "    \n",
    "    # put in some basic transit parameters\n",
    "    p.epoch    = EPOCHS[npl]\n",
    "    p.period   = PERIODS[npl]\n",
    "    p.depth    = DEPTHS[npl]\n",
    "    p.duration = DURS[npl]\n",
    "    p.impact   = IMPACTS[npl]            \n",
    "    p.radius   = RADII[npl]\n",
    "    p.ecc      = ECCS[npl]\n",
    "    p.omega    = OMEGAS[npl]\n",
    "    \n",
    "    # add transit times and indexes\n",
    "    p.tts = transit_times[npl]\n",
    "    p.index = transit_inds[npl]\n",
    "    \n",
    "    # add to list\n",
    "    planets.append(p)\n",
    "\n",
    "\n",
    "# put planets in order by period\n",
    "order = np.argsort(PERIODS)\n",
    "\n",
    "sorted_planets = []\n",
    "for npl in range(NPL):\n",
    "    sorted_planets.append(planets[order[npl]])\n",
    "\n",
    "planets = np.copy(sorted_planets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the OMC TTVs\n",
    "fig, ax = plt.subplots(NPL, figsize=(12,8))\n",
    "if NPL == 1: ax = [ax]\n",
    "\n",
    "for npl, p in enumerate(planets):\n",
    "    xtime = np.polyval(np.polyfit(p.index, p.tts, 1), p.index)\n",
    "    yomc  = (p.tts - xtime)*24*60\n",
    "    \n",
    "    ax[npl].plot(xtime, yomc, '.', c='C{0}'.format(npl))\n",
    "    ax[npl].set_ylabel('O-C [min]', fontsize=20)\n",
    "ax[NPL-1].set_xlabel('Time [BJKD]', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add synthetic transits to the lighcurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, scd in enumerate(sc_data):\n",
    "    tmin = scd.time.value.min()\n",
    "    tmax = scd.time.value.max()\n",
    "    \n",
    "    xtime = np.array(scd.time.value, dtype=\"float64\")\n",
    "    yflux = np.array(scd.flux.value, dtype=\"float64\")\n",
    "    \n",
    "    \n",
    "    # grab the transit times that are found in this quarter\n",
    "    transit_times = []\n",
    "    transit_inds  = []\n",
    "    \n",
    "    radii = []\n",
    "    impacts = []\n",
    "    periods = []\n",
    "    eccs = []\n",
    "    omegas = []\n",
    "    \n",
    "    for npl, p in enumerate(planets):\n",
    "        use = (p.tts > tmin)*(p.tts < tmax)\n",
    "        \n",
    "        if np.sum(use) > 0:\n",
    "            transit_times.append(p.tts[use])\n",
    "            transit_inds.append(p.index[use] - p.index[use].min())\n",
    "        \n",
    "            radii.append(p.radius/RSRE)\n",
    "            impacts.append(p.impact)\n",
    "            periods.append(p.period)\n",
    "            eccs.append(p.ecc)\n",
    "            omegas.append(p.omega)\n",
    "            \n",
    "    \n",
    "    if len(transit_times) > 0:\n",
    "        starrystar = exo.LimbDarkLightCurve([U1,U2])\n",
    "        orbit  = exo.orbits.TTVOrbit(transit_times=transit_times, transit_inds=transit_inds, period=periods,\n",
    "                                     b=impacts, ecc=eccs, omega=omegas, r_star=RSTAR, m_star=MSTAR)\n",
    "\n",
    "\n",
    "        light_curves = starrystar.get_light_curve(orbit=orbit, r=radii, t=xtime, oversample=1)\n",
    "        model_flux = 1.0 + pm.math.sum(light_curves, axis=-1).eval()\n",
    "\n",
    "\n",
    "        sc_data[i].flux = yflux * model_flux\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(20,4))\n",
    "        plt.plot(xtime, sc_data[i].flux, \"k.\")\n",
    "        plt.plot(xtime, model_flux, c=\"red\", lw=2)\n",
    "        plt.xlim(xtime.min(), xtime.max())\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        sc_data[i].flux = yflux * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, lcd in enumerate(lc_data):\n",
    "    tmin = lcd.time.value.min()\n",
    "    tmax = lcd.time.value.max()\n",
    "    \n",
    "    xtime = np.array(lcd.time.value, dtype=\"float64\")\n",
    "    yflux = np.array(lcd.flux.value, dtype=\"float64\")\n",
    "    \n",
    "    \n",
    "    # grab the transit times that are found in this quarter\n",
    "    transit_times = []\n",
    "    transit_inds  = []\n",
    "    \n",
    "    radii = []\n",
    "    impacts = []\n",
    "    periods = []\n",
    "    eccs = []\n",
    "    omegas = []\n",
    "    \n",
    "    for npl, p in enumerate(planets):\n",
    "        use = (p.tts > tmin)*(p.tts < tmax)\n",
    "        \n",
    "        if np.sum(use) > 0:\n",
    "            transit_times.append(p.tts[use])\n",
    "            transit_inds.append(p.index[use] - p.index[use].min())\n",
    "        \n",
    "            radii.append(p.radius/RSRE)\n",
    "            impacts.append(p.impact)\n",
    "            periods.append(p.period)\n",
    "            eccs.append(p.ecc)\n",
    "            omegas.append(p.omega)\n",
    "            \n",
    "\n",
    "    if len(transit_times) > 0:\n",
    "        starrystar = exo.LimbDarkLightCurve([U1,U2])\n",
    "        orbit  = exo.orbits.TTVOrbit(transit_times=transit_times, transit_inds=transit_inds, period=periods,\n",
    "                                     b=impacts, ecc=eccs, omega=omegas, r_star=RSTAR, m_star=MSTAR)\n",
    "\n",
    "        light_curves = starrystar.get_light_curve(orbit=orbit, r=radii, t=xtime, oversample=15)\n",
    "        model_flux = 1.0 + pm.math.sum(light_curves, axis=-1).eval()\n",
    "\n",
    "\n",
    "        lc_data[i].flux = yflux * model_flux\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(20,4))\n",
    "        plt.plot(xtime, lc_data[i].flux, \"k.\")\n",
    "        plt.plot(xtime, model_flux, c=\"red\", lw=2)\n",
    "        plt.xlim(xtime.min(), xtime.max())\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        lc_data[i].flux = yflux*1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the simulated lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_dir = SIM_DIR + \"Lightcurves/Kepler/\" + \"simkplr\" + \"{0:09d}\".format(KIC) + \"_lc/\"\n",
    "   \n",
    "if os.path.exists(lc_dir) == False:\n",
    "    os.mkdir(lc_dir)\n",
    "\n",
    "    \n",
    "for i, lcd in enumerate(lc_data):\n",
    "    fname_out = lc_dir + \"simkplr\" + \"{0:09d}\".format(KIC) + \"-q{:02d}_llc.fits\".format(lcd.quarter)\n",
    "    \n",
    "    io.save_sim_fits(lcd, path=fname_out, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_dir = SIM_DIR + \"Lightcurves/Kepler/\" + \"simkplr\" + \"{0:09d}\".format(KIC) + \"_sc/\"\n",
    "print(sc_dir)\n",
    "\n",
    "if os.path.exists(sc_dir) == False:\n",
    "    os.mkdir(sc_dir)\n",
    "\n",
    "    \n",
    "for i, scd in enumerate(sc_data):\n",
    "    fname_out = sc_dir + \"simkplr\" + \"{0:09d}\".format(KIC) + \"-q{:02d}_slc.fits\".format(scd.quarter)\n",
    "    \n",
    "    io.save_sim_fits(scd, path=fname_out, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TOTAL RUNTIME = %.2f min' %((timer()-global_start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
