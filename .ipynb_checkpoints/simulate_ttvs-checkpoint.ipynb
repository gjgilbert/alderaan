{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy.polynomial.polynomial as poly\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import importlib as imp\n",
    "from   timeit import default_timer as timer\n",
    "import rebound\n",
    "\n",
    "import alderaan.io as io\n",
    "from alderaan.constants import *\n",
    "from alderaan.utils import *\n",
    "\n",
    "global_start_time = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIMARY_DIR  = '/Users/research/projects/alderaan/'\n",
    "CSV_FILE = PRIMARY_DIR + \"Catalogs/simulated_catalog_eccentric.csv\"\n",
    "SIM_DIR  = PRIMARY_DIR + \"Simulations/TTVs/\"\n",
    "\n",
    "# check if all the paths exist and create them if not\n",
    "if os.path.exists(SIM_DIR) == False:\n",
    "    os.mkdir(SIM_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data from csv file\n",
      "Loaded 983 real KOIs\n"
     ]
    }
   ],
   "source": [
    "# Read in the data from csv file\n",
    "print('Reading in data from csv file')\n",
    "\n",
    "# read in a csv file containing info on targets\n",
    "csv_keys, csv_values = io.read_csv_file(CSV_FILE)\n",
    "\n",
    "# put these csv data into a dictionary\n",
    "catalog = {}\n",
    "for k in csv_keys: \n",
    "    catalog[k] = io.get_csv_data(k, csv_keys, csv_values)\n",
    "    \n",
    "k0 = \"koi_id\"\n",
    "    \n",
    "print(\"Loaded {0} real KOIs\".format(len(catalog[k0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datatypes\n",
    "for k in catalog.keys():\n",
    "    try:\n",
    "        catalog[k] = np.asarray(catalog[k], dtype=\"float\")\n",
    "    except:\n",
    "        catalog[k] = np.asarray(catalog[k])\n",
    "    \n",
    "    \n",
    "catalog[\"npl\"] = np.asarray(catalog[\"npl\"], dtype=\"int\")\n",
    "catalog[\"kic_id\"] = np.asarray(catalog[\"kic_id\"], dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_START = 0.\n",
    "TIME_END = 1600.\n",
    "\n",
    "# put all epochs in range (TIME_START, period)\n",
    "\n",
    "for i, koi in enumerate(catalog[\"koi_id\"]):\n",
    "    while(catalog[\"epoch\"][i] > TIME_START):\n",
    "        catalog[\"epoch\"][i] -= catalog[\"period\"][i]\n",
    "\n",
    "    catalog[\"epoch\"][i] += catalog[\"period\"][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric TTVs\n",
    "### Single planet systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, koi in enumerate(catalog[\"koi_id\"]):\n",
    "    #print(i, koi, catalog[\"ttv_type\"][i])\n",
    "    ephemeris = np.arange(catalog[\"epoch\"][i], TIME_END, catalog[\"period\"][i])\n",
    "    inds = np.arange(len(ephemeris))\n",
    "        \n",
    "    \n",
    "    # linear ttvs\n",
    "    if catalog[\"ttv_type\"][i] == \"linear\":\n",
    "        omc = np.zeros_like(ephemeris)\n",
    "        tts = ephemeris + omc\n",
    "        \n",
    "        \n",
    "    # quadratic ttvs\n",
    "    if catalog[\"ttv_type\"][i] == \"quadratic\":\n",
    "        x = 2*(ephemeris-TIME_START)/(TIME_END-TIME_START) - 1\n",
    "        Leg2 = 0.5*(3*x**2 - 1)\n",
    "        \n",
    "        scale = np.random.choice([0.1/24, catalog[\"duration\"][i]/24/3])\n",
    "        C2 = np.random.normal(loc=0, scale=scale)\n",
    "        \n",
    "        omc = C2*Leg2\n",
    "        tts = ephemeris + omc\n",
    "        \n",
    "        \n",
    "    # cubic ttvs\n",
    "    if catalog[\"ttv_type\"][i] == \"cubic\":\n",
    "        x = 2*(ephemeris-TIME_START)/(TIME_END-TIME_START) - 1\n",
    "        \n",
    "        Leg2 = 0.5*(3*x**2 - 1)\n",
    "        Leg3 = 0.5*(5*x**3 - 3*x)\n",
    "        \n",
    "        scale = np.random.choice([0.1/24, catalog[\"duration\"][i]/24/3])\n",
    "        C2, C3  = np.random.normal(loc=0, scale=scale, size=2)\n",
    "        \n",
    "        omc = C2*Leg2 + C3*Leg3\n",
    "        tts = ephemeris + omc\n",
    "        \n",
    "        \n",
    "    # sinusoidal ttvs\n",
    "    if catalog[\"ttv_type\"][i] == \"sinusoidal\":\n",
    "        fmin = 2/(TIME_END - TIME_START)\n",
    "        fmax = 1/(4*catalog[\"period\"][i])\n",
    "        logf = np.random.uniform(np.log(fmin), np.log(fmax))\n",
    "        \n",
    "        scale = np.random.choice([0.1/24, catalog[\"duration\"][i]/24/3])\n",
    "        A, B  = np.random.normal(loc=0, scale=scale, size=2)\n",
    "\n",
    "        f = np.exp(logf)\n",
    "        t = np.copy(ephemeris)\n",
    "        \n",
    "        omc = A*np.sin(2*pi*f*t) + B*np.cos(2*pi*f*t)\n",
    "        tts = ephemeris + omc        \n",
    "    \n",
    "    \n",
    "    # gaussian (white noise) ttvs\n",
    "    if catalog[\"ttv_type\"][i] == \"gaussian\":\n",
    "        scale = np.random.choice([0.1/24, catalog[\"duration\"][i]/24/3])\n",
    "        \n",
    "        omc = np.random.normal(loc=0, scale=scale, size=len(ephemeris))\n",
    "        tts = ephemeris + omc\n",
    "        \n",
    "        \n",
    "    # ultra-short period TTVs treated as linear\n",
    "    if catalog[\"ttv_type\"][i] == \"usp\":\n",
    "        omc = np.zeros_like(ephemeris)\n",
    "        tts = ephemeris + omc\n",
    "    \n",
    "    \n",
    "    # grazing TTVs also treated as linear\n",
    "    if catalog[\"ttv_type\"][i] == \"grazing\":\n",
    "        omc = np.zeros_like(ephemeris)\n",
    "        tts = ephemeris + omc\n",
    "        \n",
    "        \n",
    "    # save the results\n",
    "    if (catalog[\"npl\"][i] == 1):\n",
    "        data_out  = np.vstack([inds, tts]).swapaxes(0,1)\n",
    "        fname_out = SIM_DIR + \"S\" + koi[1:] + '_00_sim_ttvs.txt'\n",
    "\n",
    "        np.savetxt(fname_out, data_out, fmt=('%1d', '%.8f'), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-planet systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentric_doubles = np.unique(catalog[\"koi_id\"][catalog[\"ttv_type\"] == \"eccentric\"])\n",
    "\n",
    "ecc_new = []\n",
    "omega_new = []\n",
    "\n",
    "for i, koi in enumerate(eccentric_doubles):\n",
    "    use = catalog[\"koi_id\"] == koi\n",
    "    npl = catalog[\"npl\"][use][0]\n",
    "    \n",
    "    per = catalog[\"period\"][use]\n",
    "    t0 = catalog[\"epoch\"][use]\n",
    "    \n",
    "    for j in range(npl):\n",
    "        ephemeris = np.arange(t0[j], TIME_END, per[j])\n",
    "        inds = np.arange(len(ephemeris))\n",
    "    \n",
    "        data_out  = np.vstack([inds, ephemeris]).swapaxes(0,1)\n",
    "        fname_out = SIM_DIR + \"S\" + koi[1:] + '_{:02d}'.format(j) + '_sim_ttvs.txt'\n",
    "\n",
    "        np.savetxt(fname_out, data_out, fmt=('%1d', '%.8f'), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-body simulations with REBOUND\n",
    "### Multiplanet systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(Mstar, mass, per, ecc, omega, mean_anomaly):\n",
    "    \"\"\"\n",
    "    Docstring\n",
    "    \"\"\"\n",
    "    \n",
    "    NPL = len(mass)\n",
    "    sma = get_sma(per, Mstar)*RSAU\n",
    "    \n",
    "    \n",
    "    # set up simulation\n",
    "    sim = rebound.Simulation()\n",
    "    sim.units = (\"AU\", \"Msun\", \"days\")\n",
    "    sim.add(m=Mstar)\n",
    "\n",
    "    for npl in range(NPL):\n",
    "        sim.add(m=mass[npl], a=sma[npl], e=ecc[npl], omega=omega[npl], M=mean_anomaly[npl])\n",
    "\n",
    "    p = sim.particles\n",
    "    \n",
    "                                                                 \n",
    "    # do the integration\n",
    "    transit_times = []\n",
    "\n",
    "    for npl in range(NPL):\n",
    "        transit_times.append([])\n",
    "\n",
    "        while sim.t < 1600:\n",
    "            y_old = p[npl+1].y - p[0].y\n",
    "\n",
    "            t_old = sim.t\n",
    "            sim.integrate(sim.t + per.min()/20)\n",
    "            t_new = sim.t\n",
    "\n",
    "            # sign of y changes and planet is in front of star (x > 0)\n",
    "            if y_old*(p[npl+1].y-p[0].y) < 0 and p[npl+1].x-p[0].x > 0:\n",
    "\n",
    "                # bisect until precision is reached\n",
    "                while t_new-t_old > 1e-7:\n",
    "                    if y_old*(p[npl+1].y-p[0].y) < 0:\n",
    "                        t_new = sim.t\n",
    "                    else:\n",
    "                        t_old = sim.t\n",
    "                    sim.integrate( (t_new+t_old)/2)\n",
    "\n",
    "                transit_times[npl].append(sim.t)\n",
    "\n",
    "               # integrate 0.05 to be past the transit        \n",
    "                sim.integrate(sim.t + per.min()/20)\n",
    "\n",
    "        sim.integrate(0.)\n",
    "        \n",
    "    return transit_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 K00041\n",
      "1 K00116\n",
      "2 K00172\n",
      "3 K00216\n",
      "4 K00222\n",
      "5 K00244\n",
      "6 K00253\n",
      "7 K00260\n",
      "8 K00266\n",
      "9 K00270\n",
      "10 K00271\n",
      "11 K00282\n",
      "12 K00283\n",
      "13 K00284\n",
      "14 K00298\n",
      "15 K00301\n",
      "16 K00304\n",
      "17 K00307\n",
      "18 K00313\n",
      "19 K00314\n",
      "20 K00316\n",
      "21 K00317\n",
      "22 K00337\n",
      "23 K00354\n",
      "24 K00386\n",
      "25 K00413\n",
      "26 K00416\n",
      "27 K00427\n",
      "28 K00430\n",
      "29 K00459\n",
      "30 K00471\n",
      "31 K00474\n",
      "32 K00475\n",
      "33 K00508\n",
      "34 K00520\n",
      "35 K00521\n",
      "36 K00528\n",
      "37 K00542\n",
      "38 K00546\n",
      "39 K00547\n",
      "40 K00548\n",
      "41 K00551\n",
      "42 K00566\n",
      "43 K00567\n",
      "44 K00574\n",
      "45 K00581\n",
      "46 K00582\n",
      "47 K00584\n",
      "48 K00590\n",
      "49 K00623\n",
      "50 K00626\n",
      "51 K00638\n",
      "52 K00645\n",
      "53 K00647\n",
      "54 K00654\n",
      "55 K00679\n",
      "56 K00693\n",
      "57 K00700\n",
      "58 K00708\n",
      "59 K00730\n",
      "60 K00734\n",
      "61 K00736\n",
      "62 K00759\n",
      "63 K00775\n",
      "64 K00784\n",
      "65 K00790\n",
      "66 K00806\n",
      "67 K00829\n",
      "68 K00842\n",
      "69 K00870\n",
      "70 K00877\n",
      "71 K00886\n",
      "72 K00896\n",
      "73 K00912\n",
      "74 K00934\n",
      "75 K00935\n",
      "76 K00951\n",
      "77 K00988\n",
      "78 K00999\n",
      "79 K01101\n",
      "80 K01106\n",
      "81 K01113\n",
      "82 K01148\n",
      "83 K01236\n",
      "84 K01270\n",
      "85 K01276\n",
      "86 K01366\n",
      "87 K01404\n",
      "88 K01426\n",
      "89 K01435\n",
      "90 K01519\n",
      "91 K01522\n",
      "92 K01529\n",
      "93 K01534\n",
      "94 K01593\n",
      "95 K01598\n",
      "96 K01613\n",
      "97 K01616\n",
      "98 K01707\n",
      "99 K01751\n",
      "100 K01788\n",
      "101 K01792\n",
      "102 K01830\n",
      "103 K01871\n",
      "104 K01874\n",
      "105 K01895\n",
      "106 K01905\n",
      "107 K01908\n",
      "108 K01909\n",
      "109 K01952\n",
      "110 K01960\n",
      "111 K01977\n",
      "112 K01978\n",
      "113 K01986\n",
      "114 K02012\n",
      "115 K02022\n",
      "116 K02025\n",
      "117 K02038\n",
      "118 K02045\n",
      "119 K02051\n",
      "120 K02080\n",
      "121 K02113\n",
      "122 K02147\n",
      "123 K02153\n",
      "124 K02162\n",
      "125 K02163\n",
      "126 K02195\n",
      "127 K02243\n",
      "128 K02257\n",
      "129 K02264\n",
      "130 K02279\n",
      "131 K02287\n",
      "132 K02327\n",
      "133 K02413\n",
      "134 K02442\n",
      "135 K02554\n",
      "136 K02563\n",
      "137 K02585\n",
      "138 K02595\n",
      "139 K02597\n",
      "140 K02672\n",
      "141 K02681\n",
      "142 K02707\n",
      "143 K02714\n",
      "144 K02732\n",
      "145 K02857\n",
      "146 K02871\n",
      "147 K02906\n",
      "148 K02971\n",
      "149 K03052\n",
      "150 K03061\n",
      "151 K03083\n",
      "152 K03130\n",
      "153 K03138\n",
      "154 K03384\n",
      "155 K03401\n",
      "156 K03456\n",
      "157 K03503\n",
      "158 K03681\n",
      "159 K03936\n",
      "160 K04103\n",
      "161 K04246\n",
      "162 K04288\n",
      "163 K04477\n",
      "164 K04541\n",
      "165 K04657\n",
      "166 K04773\n",
      "167 K04838\n",
      "168 K04895\n",
      "169 K04896\n",
      "170 K06182\n",
      "171 K06245\n",
      "172 K07117\n",
      "173 K07685\n"
     ]
    }
   ],
   "source": [
    "rebound_systems = np.unique(catalog[\"koi_id\"][catalog[\"ttv_type\"] == \"rebound\"])\n",
    "\n",
    "ecc_new = []\n",
    "omega_new = []\n",
    "\n",
    "for i, koi in enumerate(rebound_systems):\n",
    "    print(i, koi)\n",
    "    \n",
    "    # get parameters from simulated catalog\n",
    "    use = catalog[\"koi_id\"] == koi\n",
    "    \n",
    "    npl    = catalog[\"npl\"][use][0]\n",
    "    Mstar  = catalog[\"mstar\"][use][0]\n",
    "    mass   = catalog[\"pmass\"][use]/MSME\n",
    "    per    = catalog[\"period\"][use]\n",
    "    M_anom = np.random.uniform(0, 2*pi, npl)\n",
    "    \n",
    "    \n",
    "    # draw eccentricity vectors (see Lithwick, Xie, & Wu 2012)\n",
    "    ecc = np.ones(npl)\n",
    "    while np.any(ecc > 0.4):\n",
    "        esinw, ecosw = np.random.normal(loc=0, scale=0.008, size=2*npl).reshape((2,npl))\n",
    "\n",
    "        ecc = np.sqrt(esinw**2 + ecosw**2)\n",
    "        omega = np.arctan2(esinw, ecosw)\n",
    "    \n",
    "    \n",
    "    for e0 in ecc:\n",
    "        ecc_new.append(e0)\n",
    "    for w0 in omega:\n",
    "        omega_new.append(w0)\n",
    "        \n",
    "    \n",
    "    # integrate REBOUND to get transit times\n",
    "    transit_times = run_simulation(Mstar, mass, per, ecc, omega, M_anom)    \n",
    "    \n",
    "    transit_inds  = []\n",
    "    for j in range(npl):\n",
    "        transit_inds.append(np.arange(len(transit_times[j])))\n",
    "        \n",
    "        \n",
    "    # save the results\n",
    "    for j in range(npl):\n",
    "        data_out  = np.vstack([transit_inds[j], transit_times[j]]).swapaxes(0,1)\n",
    "        fname_out = SIM_DIR + \"S\" + koi[1:] + '_{:02d}'.format(j) + '_sim_ttvs.txt'\n",
    "\n",
    "        np.savetxt(fname_out, data_out, fmt=('%1d', '%.8f'), delimiter='\\t')\n",
    "        \n",
    "\n",
    "# update eccentricity vectors in the catalog\n",
    "replace = catalog[\"ttv_type\"] == \"rebound\"\n",
    "\n",
    "catalog[\"ecc\"][replace] = ecc_new\n",
    "catalog[\"omega\"][replace] = omega_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update periods and epochs to least squares fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_lsq = []\n",
    "period_lsq = []\n",
    "\n",
    "\n",
    "for i, koi in enumerate(catalog[\"koi_id\"]):\n",
    "    use = catalog[\"koi_id\"] == koi\n",
    "    npl = np.sum(use)\n",
    "    \n",
    "    # this if statement avoids double counting multiplant systems\n",
    "    if len(period_lsq) <= i:\n",
    "        for j in range(npl):\n",
    "            data_in = np.loadtxt(SIM_DIR + \"S\" + koi[1:] + '_{:02d}'.format(j) + '_sim_ttvs.txt')\n",
    "            inds, tts = np.atleast_2d(data_in).swapaxes(0,1)\n",
    "\n",
    "            if len(tts) > 1:\n",
    "                pfit = poly.polyfit(inds, tts, 1)\n",
    "\n",
    "                epoch_lsq.append(pfit[0])\n",
    "                period_lsq.append(pfit[1])\n",
    "\n",
    "            else:\n",
    "                epoch_lsq.append(tts[0])\n",
    "                period_lsq.append(catalog[\"period\"][use][j])\n",
    "                \n",
    "\n",
    "catalog[\"epoch\"] = np.asarray(epoch_lsq)\n",
    "catalog[\"period\"] = np.asarray(period_lsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update transit durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculate transit durations\n",
    "sma = get_sma(catalog[\"period\"], catalog[\"mstar\"])\n",
    "\n",
    "catalog[\"duration\"] = 24*get_dur_tot(catalog[\"period\"], \n",
    "                                     catalog[\"prad\"]/RSRE, \n",
    "                                     catalog[\"rstar\"],\n",
    "                                     catalog[\"impact\"],\n",
    "                                     sma,\n",
    "                                     catalog[\"ecc\"],\n",
    "                                     catalog[\"omega\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do some cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = list(catalog.keys())\n",
    "int_keys = ['kic_id', 'npl', 'depth']\n",
    "string_keys = ['planet_name', 'disposition', 'koi_id', 'ttv_type']\n",
    "precise_keys = ['period', 'epoch']\n",
    "\n",
    "\n",
    "for k in catalog.keys():\n",
    "    if np.isin(k, int_keys):\n",
    "        catalog[k] = np.array(catalog[k], dtype=\"int\")\n",
    "    elif np.isin(k, string_keys):\n",
    "        catalog[k] = catalog[k]\n",
    "    elif np.isin(k, precise_keys):\n",
    "        catalog[k] = np.round(np.array(catalog[k], dtype=\"float\"), 5)\n",
    "    else:\n",
    "        catalog[k] = np.round(np.array(catalog[k], dtype=\"float\"), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITENEW = True\n",
    "if WRITENEW:\n",
    "    with open(CSV_FILE, \"w\") as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(catalog.keys())\n",
    "        writer.writerows(zip(*catalog.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL RUNTIME = 2.68 min\n"
     ]
    }
   ],
   "source": [
    "print('TOTAL RUNTIME = %.2f min' %((timer()-global_start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
